{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 0.项目可直接运行\n",
    "\n",
    "需要注意配置文件：\n",
    "\n",
    "use_gpu: True\n",
    "\n",
    "epoch: 30\n",
    "\n",
    "项目是中文转英文\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.中英文机器翻译\n",
    "\n",
    "使用PaddlePaddle 实现，包含模型训练，预测以及使用自定义数据等内容。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "# 2. 模型描述\n",
    "Transformer 是完成序列到序列（Seq2Seq）学习任务的一种全新网络结构，其完全使用注意力（Attention）机制来实现序列到序列的建模。\n",
    "\n",
    "相较于此前 Seq2Seq 模型中广泛使用的循环神经网络（Recurrent Neural Network, RNN），使用Self Attention进行输入序列到输出序列的变换主要具有以下优势：\n",
    "\n",
    "- 计算复杂度小\n",
    "\t- 特征维度为 d 、长度为 n 的序列，在 RNN 中计算复杂度为 O(n * d * d) （n 个时间步，每个时间步计算 d 维的矩阵向量乘法），在 Self-Attention 中计算复杂度为 O(n * n * d) （n 个时间步两两计算 d 维的向量点积或其他相关度函数），n 通常要小于 d 。\n",
    "- 计算并行度高\n",
    "\t- RNN 中当前时间步的计算要依赖前一个时间步的计算结果；Self-Attention 中各时间步的计算只依赖输入不依赖之前时间步输出，各时间步可以完全并行。\n",
    "- 容易学习长距离依赖（long-range dependencies）\n",
    "\t- RNN 中相距为 n 的两个位置间的关联需要 n 步才能建立；Self-Attention 中任何两个位置都直接相连；路径越短信号传播越容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.1 Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.fluid import layers\n",
    "\n",
    "class MultiHeadAttention(nn.Layer):\n",
    "\n",
    "    Cache = collections.namedtuple(\"Cache\", [\"k\", \"v\"])\n",
    "    StaticCache = collections.namedtuple(\"StaticCache\", [\"k\", \"v\"])\n",
    "    \n",
    "    def __init__(self,\n",
    "                 embed_dim,\n",
    "                 num_heads,\n",
    "                 dropout=0.,\n",
    "                 kdim=None,\n",
    "                 vdim=None,\n",
    "                 need_weights=False,\n",
    "                 weight_attr=None,\n",
    "                 bias_attr=None):   \n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # 输入的embedding维度\n",
    "        self.embed_dim = embed_dim\n",
    "        # key的维度\n",
    "        self.kdim = kdim if kdim is not None else embed_dim\n",
    "        # value的维度\n",
    "        self.vdim = vdim if vdim is not None else embed_dim\n",
    "        # head的数目\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.need_weights = need_weights\n",
    "\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.embed_dim, \"embed_dim must be divisible by num_heads\"\n",
    "        # query\n",
    "        self.q_proj = Linear(\n",
    "            embed_dim, embed_dim, weight_attr, bias_attr=bias_attr)\n",
    "        # key\n",
    "        self.k_proj = Linear(\n",
    "            self.kdim, embed_dim, weight_attr, bias_attr=bias_attr)\n",
    "        # value\n",
    "        self.v_proj = Linear(\n",
    "            self.vdim, embed_dim, weight_attr, bias_attr=bias_attr)\n",
    "        self.out_proj = Linear(\n",
    "            embed_dim, embed_dim, weight_attr, bias_attr=bias_attr)\n",
    "\n",
    "    def _prepare_qkv(self, query, key, value, cache=None):\n",
    "        q = self.q_proj(query)\n",
    "        q = tensor.reshape(x=q, shape=[0, 0, self.num_heads, self.head_dim])\n",
    "        q = tensor.transpose(x=q, perm=[0, 2, 1, 3])\n",
    "\n",
    "        if isinstance(cache, self.StaticCache):\n",
    "            # for encoder-decoder attention in inference and has cached\n",
    "            k, v = cache.k, cache.v\n",
    "        else:\n",
    "            k, v = self.compute_kv(key, value)\n",
    "\n",
    "        if isinstance(cache, self.Cache):\n",
    "            # for decoder self-attention in inference\n",
    "            k = tensor.concat([cache.k, k], axis=2)\n",
    "            v = tensor.concat([cache.v, v], axis=2)\n",
    "\n",
    "        return (q, k, v) if cache is None else (q, k, v, cache)\n",
    "\n",
    "    def compute_kv(self, key, value):\n",
    "        k = self.k_proj(key)\n",
    "        v = self.v_proj(value)\n",
    "        k = tensor.reshape(x=k, shape=[0, 0, self.num_heads, self.head_dim])\n",
    "        k = tensor.transpose(x=k, perm=[0, 2, 1, 3])\n",
    "        v = tensor.reshape(x=v, shape=[0, 0, self.num_heads, self.head_dim])\n",
    "        v = tensor.transpose(x=v, perm=[0, 2, 1, 3])\n",
    "        return k, v\n",
    "\n",
    "    def forward(self, query, key=None, value=None, attn_mask=None, cache=None):\n",
    "        key = query if key is None else key\n",
    "        value = query if value is None else value\n",
    "        # compute q ,k ,v\n",
    "       \n",
    "        q, k, v = self._prepare_qkv(query, key, value, cache)\n",
    "       \n",
    "\n",
    "        # scale dot product attention\n",
    "        product = layers.matmul(\n",
    "            x=q, y=k, transpose_y=True, alpha=self.head_dim**-0.5)\n",
    "        if attn_mask is not None:\n",
    "            # Support bool or int mask\n",
    "            attn_mask = _convert_attention_mask(attn_mask, product.dtype)\n",
    "            product = product + attn_mask\n",
    "        weights = F.softmax(product)\n",
    "        if self.dropout:\n",
    "            weights = F.dropout(\n",
    "                weights,\n",
    "                self.dropout,\n",
    "                training=self.training,\n",
    "                mode=\"upscale_in_train\")\n",
    "\n",
    "        out = tensor.matmul(weights, v)\n",
    "\n",
    "        # combine heads\n",
    "        out = tensor.transpose(out, perm=[0, 2, 1, 3])\n",
    "        out = tensor.reshape(x=out, shape=[0, 0, out.shape[2] * out.shape[3]])\n",
    "\n",
    "        # project to output\n",
    "        out = self.out_proj(out)\n",
    "\n",
    "        outs = [out]\n",
    "        if self.need_weights:\n",
    "            outs.append(weights)\n",
    "\n",
    "        return out if len(outs) == 1 else tuple(outs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _convert_attention_mask(attn_mask, dtype):\n",
    "    if attn_mask is not None and attn_mask.dtype != dtype:\n",
    "        attn_mask_dtype = convert_dtype(attn_mask.dtype)\n",
    "        if attn_mask_dtype == 'bool' or 'int' in attn_mask_dtype:\n",
    "            attn_mask = (paddle.cast(attn_mask, dtype) - 1.0) * 1e9\n",
    "        else:\n",
    "            attn_mask = paddle.cast(attn_mask, dtype)\n",
    "    return attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _convert_param_attr_to_list(param_attr, n):\n",
    "    if isinstance(param_attr, (list, tuple)):\n",
    "        assert len(param_attr) == n, (\n",
    "            \"length of param_attr should be %d when it is a list/tuple\" % n)\n",
    "        param_attrs = []\n",
    "        for attr in param_attr:\n",
    "            if isinstance(attr, bool):\n",
    "                if attr:\n",
    "                    param_attrs.append(ParamAttr._to_attr(None))\n",
    "                else:\n",
    "                    param_attrs.append(False)\n",
    "            else:\n",
    "                param_attrs.append(ParamAttr._to_attr(attr))\n",
    "        # param_attrs = [ParamAttr._to_attr(attr) for attr in param_attr]\n",
    "    elif isinstance(param_attr, bool):\n",
    "        param_attrs = []\n",
    "        if param_attr:\n",
    "            param_attrs = [ParamAttr._to_attr(None) for i in range(n)]\n",
    "        else:\n",
    "            param_attrs = [False] * n\n",
    "    else:\n",
    "        param_attrs = []\n",
    "        attr = ParamAttr._to_attr(param_attr)\n",
    "        for i in range(n):\n",
    "            attr_i = copy.deepcopy(attr)\n",
    "            if attr.name:\n",
    "                attr_i.name = attr_i.name + \"_\" + str(i)\n",
    "            param_attrs.append(attr_i)\n",
    "    return param_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward,\n",
    "                 dropout=0.1,\n",
    "                 activation=\"relu\",\n",
    "                 attn_dropout=None,\n",
    "                 act_dropout=None,\n",
    "                 normalize_before=False,\n",
    "                 weight_attr=None,\n",
    "                 bias_attr=None):\n",
    "        self._config = locals()\n",
    "        self._config.pop(\"self\")\n",
    "        self._config.pop(\"__class__\", None)  # py3\n",
    "\n",
    "        super(TransformerEncoderLayer, self).__init__()\n",
    "        attn_dropout = dropout if attn_dropout is None else attn_dropout\n",
    "        act_dropout = dropout if act_dropout is None else act_dropout\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        weight_attrs = _convert_param_attr_to_list(weight_attr, 2)\n",
    "        bias_attrs = _convert_param_attr_to_list(bias_attr, 2)\n",
    "\n",
    "        # multi head attention\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            d_model,\n",
    "            nhead,\n",
    "            dropout=attn_dropout,\n",
    "            weight_attr=weight_attrs[0],\n",
    "            bias_attr=bias_attrs[0])\n",
    "        \n",
    "        # feed forward\n",
    "        self.linear1 = Linear(\n",
    "            d_model, dim_feedforward, weight_attrs[1], bias_attr=bias_attrs[1])\n",
    "        self.dropout = Dropout(act_dropout, mode=\"upscale_in_train\")\n",
    "        self.linear2 = Linear(\n",
    "            dim_feedforward, d_model, weight_attrs[1], bias_attr=bias_attrs[1])\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model)\n",
    "        self.dropout1 = Dropout(dropout, mode=\"upscale_in_train\")\n",
    "        self.dropout2 = Dropout(dropout, mode=\"upscale_in_train\")\n",
    "        self.activation = getattr(F, activation)\n",
    "    \n",
    "    def forward(self, src, src_mask=None, cache=None):\n",
    "        src_mask = _convert_attention_mask(src_mask, src.dtype)\n",
    "\n",
    "        residual = src\n",
    "\n",
    "        #  multi head attention \n",
    "        src = self.self_attn(src, src, src, src_mask)\n",
    "        # 残差连接\n",
    "        src = residual + self.dropout1(src)\n",
    "        # Norm\n",
    "        src = self.norm1(src)\n",
    "        residual = src\n",
    "\n",
    "        # feed forward\n",
    "        src = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        # 残差连接\n",
    "        src = residual + self.dropout2(src)\n",
    "        # Norm\n",
    "        src = self.norm2(src)\n",
    "        return src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Layer):\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 nhead,\n",
    "                 dim_feedforward,\n",
    "                 dropout=0.1,\n",
    "                 activation=\"relu\",\n",
    "                 attn_dropout=None,\n",
    "                 act_dropout=None,\n",
    "                 normalize_before=False,\n",
    "                 weight_attr=None,\n",
    "                 bias_attr=None):\n",
    "        self._config = locals()\n",
    "        self._config.pop(\"self\")\n",
    "        self._config.pop(\"__class__\", None)  # py3\n",
    "\n",
    "        super(TransformerDecoderLayer, self).__init__()\n",
    "        attn_dropout = dropout if attn_dropout is None else attn_dropout\n",
    "        act_dropout = dropout if act_dropout is None else act_dropout\n",
    "        self.normalize_before = normalize_before\n",
    "\n",
    "        weight_attrs = _convert_param_attr_to_list(weight_attr, 3)\n",
    "        bias_attrs = _convert_param_attr_to_list(bias_attr, 3)\n",
    "        # multi head attention\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            d_model,\n",
    "            nhead,\n",
    "            dropout=attn_dropout,\n",
    "            weight_attr=weight_attrs[0],\n",
    "            bias_attr=bias_attrs[0])\n",
    "        # encoder decoder attention\n",
    "        self.cross_attn = MultiHeadAttention(\n",
    "            d_model,\n",
    "            nhead,\n",
    "            dropout=attn_dropout,\n",
    "            weight_attr=weight_attrs[1],\n",
    "            bias_attr=bias_attrs[1])\n",
    "        # feed forward\n",
    "        self.linear1 = Linear(\n",
    "            d_model, dim_feedforward, weight_attrs[2], bias_attr=bias_attrs[2])\n",
    "        self.dropout = nn.Dropout(act_dropout, mode=\"upscale_in_train\")\n",
    "        self.linear2 = Linear(\n",
    "            dim_feedforward, d_model, weight_attrs[2], bias_attr=bias_attrs[2])\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout, mode=\"upscale_in_train\")\n",
    "        self.dropout2 = nn.Dropout(dropout, mode=\"upscale_in_train\")\n",
    "        self.dropout3 = nn.Dropout(dropout, mode=\"upscale_in_train\")\n",
    "        self.activation = getattr(F, activation)\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None, cache=None):\n",
    "        tgt_mask = _convert_attention_mask(tgt_mask, tgt.dtype)\n",
    "        memory_mask = _convert_attention_mask(memory_mask, memory.dtype)\n",
    "\n",
    "        residual = tgt\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm1(tgt)\n",
    "        if cache is None:\n",
    "            tgt = self.self_attn(tgt, tgt, tgt, tgt_mask, None)\n",
    "        else:\n",
    "            tgt, incremental_cache = self.self_attn(tgt, tgt, tgt, tgt_mask,\n",
    "                                                    cache[0])\n",
    "        # 残差连接\n",
    "        tgt = residual + self.dropout1(tgt)\n",
    "        # Norm\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm1(tgt)\n",
    "\n",
    "        residual = tgt\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm2(tgt)\n",
    "        if cache is None:\n",
    "            tgt = self.cross_attn(tgt, memory, memory, memory_mask, None)\n",
    "        else:\n",
    "            tgt, static_cache = self.cross_attn(tgt, memory, memory,\n",
    "                                                memory_mask, cache[1])\n",
    "        # 残差连接\n",
    "        tgt = residual + self.dropout2(tgt) \n",
    "        # Norm\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm2(tgt)\n",
    "\n",
    "        residual = tgt\n",
    "        if self.normalize_before:\n",
    "            tgt = self.norm3(tgt)\n",
    "        tgt = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        # 残差连接\n",
    "        tgt = residual + self.dropout3(tgt)\n",
    "        # Norm\n",
    "        if not self.normalize_before:\n",
    "            tgt = self.norm3(tgt)\n",
    "        return tgt if cache is None else (tgt, (incremental_cache,\n",
    "                                                static_cache))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3、训练与预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1  环境介绍\n",
    "\n",
    "- PaddlePaddle框架，AI Studio平台已经默认安装最新版2.0。\n",
    "\n",
    "- PaddleNLP，深度兼容框架2.0，是飞桨框架2.0在NLP领域的最佳实践。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting subword_nmt==0.3.7\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Installing collected packages: subword_nmt\n",
      "Successfully installed subword_nmt-0.3.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting attrdict==2.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from attrdict==2.0.1) (1.16.0)\n",
      "Installing collected packages: attrdict\n",
      "Successfully installed attrdict-2.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlenlp==2.0.0rc22\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5a/c9/c50fefbc009f900e207bcfa6e577052ec9b6c0f8134c4bb89aa00851c49a/paddlenlp-2.0.0rc22-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m405.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (4.1.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (0.70.11.1)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (0.4.4)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (2.9.0)\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (2.2.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (1.2.2)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp==2.0.0rc22) (0.42.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp==2.0.0rc22) (1.20.3)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp==2.0.0rc22) (1.16.0)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp==2.0.0rc22) (0.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp==2.0.0rc22) (0.24.2)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (4.0.1)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (1.21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (2.22.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (1.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (1.0.0)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (8.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (2.2.3)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (0.8.53)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (1.1.5)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (0.7.1.1)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl->paddlenlp==2.0.0rc22) (3.20.1)\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (4.2.0)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (2.4.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (0.6.1)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (2.8.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp==2.0.0rc22) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp==2.0.0rc22) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp==2.0.0rc22) (3.0.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl->paddlenlp==2.0.0rc22) (1.1.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp==2.0.0rc22) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl->paddlenlp==2.0.0rc22) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.0.0rc22) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.0.0rc22) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp==2.0.0rc22) (1.6.3)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp==2.0.0rc22) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl->paddlenlp==2.0.0rc22) (3.9.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp==2.0.0rc22) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp==2.0.0rc22) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp==2.0.0rc22) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl->paddlenlp==2.0.0rc22) (3.0.9)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (0.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (5.1.2)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (1.3.4)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (16.7.9)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (1.4.10)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (2.0.1)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl->paddlenlp==2.0.0rc22) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp==2.0.0rc22) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp==2.0.0rc22) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp==2.0.0rc22) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl->paddlenlp==2.0.0rc22) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl->paddlenlp==2.0.0rc22) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl->paddlenlp==2.0.0rc22) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl->paddlenlp==2.0.0rc22) (56.2.0)\n",
      "Installing collected packages: paddlenlp\n",
      "  Attempting uninstall: paddlenlp\n",
      "    Found existing installation: paddlenlp 2.0.7\n",
      "    Uninstalling paddlenlp-2.0.7:\n",
      "      Successfully uninstalled paddlenlp-2.0.7\n",
      "Successfully installed paddlenlp-2.0.0rc22\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖\n",
    "# !pip install -r requirements.txt\n",
    "!pip install subword_nmt==0.3.7\n",
    "!pip install attrdict==2.0.1\n",
    "!pip install paddlenlp==2.0.0rc22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/attrdict/mapping.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/attrdict/mixins.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from attrdict import AttrDict\n",
    "import jieba\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from functools import partial\n",
    "\n",
    "import paddle\n",
    "import paddle.distributed as dist\n",
    "from paddle.io import DataLoader\n",
    "from paddlenlp.data import Vocab, Pad\n",
    "from paddlenlp.data.sampler import SamplerHelper\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.transformers import TransformerModel, InferTransformerModel, CrossEntropyCriterion, position_encoding_init\n",
    "from paddlenlp.utils.log import logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01/\n",
      "2015-01/subeval_files/\n",
      "2015-01/._subjeval.html\n",
      "2015-01/subjeval.html\n",
      "2015-01/texts/\n",
      "2015-01/._texts.html\n",
      "2015-01/texts.html\n",
      "2015-01/._tools.html\n",
      "2015-01/tools.html\n",
      "2015-01/texts/cs/\n",
      "2015-01/texts/de/\n",
      "2015-01/texts/en/\n",
      "2015-01/texts/fr/\n",
      "2015-01/texts/th/\n",
      "2015-01/texts/vi/\n",
      "2015-01/texts/zh/\n",
      "2015-01/texts/zh/en/\n",
      "2015-01/texts/zh/en/._.eval\n",
      "2015-01/texts/zh/en/.eval\n",
      "2015-01/texts/zh/en/._.info\n",
      "2015-01/texts/zh/en/.info\n",
      "2015-01/texts/zh/en/._zh-en.tgz\n",
      "2015-01/texts/zh/en/zh-en.tgz\n",
      "2015-01/texts/vi/en/\n",
      "2015-01/texts/vi/en/._.eval\n",
      "2015-01/texts/vi/en/.eval\n",
      "2015-01/texts/vi/en/._.info\n",
      "2015-01/texts/vi/en/.info\n",
      "2015-01/texts/vi/en/._vi-en.tgz\n",
      "2015-01/texts/vi/en/vi-en.tgz\n",
      "2015-01/texts/th/en/\n",
      "2015-01/texts/th/en/._.eval\n",
      "2015-01/texts/th/en/.eval\n",
      "2015-01/texts/th/en/._.info\n",
      "2015-01/texts/th/en/.info\n",
      "2015-01/texts/th/en/._th-en.tgz\n",
      "2015-01/texts/th/en/th-en.tgz\n",
      "2015-01/texts/fr/en/\n",
      "2015-01/texts/fr/en/._.eval\n",
      "2015-01/texts/fr/en/.eval\n",
      "2015-01/texts/fr/en/._.info\n",
      "2015-01/texts/fr/en/.info\n",
      "2015-01/texts/fr/en/._fr-en.tgz\n",
      "2015-01/texts/fr/en/fr-en.tgz\n",
      "2015-01/texts/en/cs/\n",
      "2015-01/texts/en/de/\n",
      "2015-01/texts/en/fr/\n",
      "2015-01/texts/en/th/\n",
      "2015-01/texts/en/vi/\n",
      "2015-01/texts/en/zh/\n",
      "2015-01/texts/en/zh/._.eval\n",
      "2015-01/texts/en/zh/.eval\n",
      "2015-01/texts/en/zh/._.info\n",
      "2015-01/texts/en/zh/.info\n",
      "2015-01/texts/en/zh/._en-zh.tgz\n",
      "2015-01/texts/en/zh/en-zh.tgz\n",
      "2015-01/texts/en/vi/._.eval\n",
      "2015-01/texts/en/vi/.eval\n",
      "2015-01/texts/en/vi/._.info\n",
      "2015-01/texts/en/vi/.info\n",
      "2015-01/texts/en/vi/._en-vi.tgz\n",
      "2015-01/texts/en/vi/en-vi.tgz\n",
      "2015-01/texts/en/th/._.eval\n",
      "2015-01/texts/en/th/.eval\n",
      "2015-01/texts/en/th/._.info\n",
      "2015-01/texts/en/th/.info\n",
      "2015-01/texts/en/th/._en-th.tgz\n",
      "2015-01/texts/en/th/en-th.tgz\n",
      "2015-01/texts/en/fr/._.eval\n",
      "2015-01/texts/en/fr/.eval\n",
      "2015-01/texts/en/fr/._.info\n",
      "2015-01/texts/en/fr/.info\n",
      "2015-01/texts/en/fr/._en-fr.tgz\n",
      "2015-01/texts/en/fr/en-fr.tgz\n",
      "2015-01/texts/en/de/._.eval\n",
      "2015-01/texts/en/de/.eval\n",
      "2015-01/texts/en/de/._.info\n",
      "2015-01/texts/en/de/.info\n",
      "2015-01/texts/en/de/._en-de.tgz\n",
      "2015-01/texts/en/de/en-de.tgz\n",
      "2015-01/texts/en/cs/._.eval\n",
      "2015-01/texts/en/cs/.eval\n",
      "2015-01/texts/en/cs/._.info\n",
      "2015-01/texts/en/cs/.info\n",
      "2015-01/texts/en/cs/._en-cs.tgz\n",
      "2015-01/texts/en/cs/en-cs.tgz\n",
      "2015-01/texts/de/en/\n",
      "2015-01/texts/de/en/._.eval\n",
      "2015-01/texts/de/en/.eval\n",
      "2015-01/texts/de/en/._.info\n",
      "2015-01/texts/de/en/.info\n",
      "2015-01/texts/de/en/._de-en.tgz\n",
      "2015-01/texts/de/en/de-en.tgz\n",
      "2015-01/texts/cs/en/\n",
      "2015-01/texts/cs/en/._.eval\n",
      "2015-01/texts/cs/en/.eval\n",
      "2015-01/texts/cs/en/._.info\n",
      "2015-01/texts/cs/en/.info\n",
      "2015-01/texts/cs/en/._cs-en.tgz\n",
      "2015-01/texts/cs/en/cs-en.tgz\n",
      "2015-01/subeval_files/._IWSLT15-HE-RELEASE.zip\n",
      "2015-01/subeval_files/IWSLT15-HE-RELEASE.zip\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf data/data92803/2015-01.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh-en/\n",
      "zh-en/IWSLT15.TED.dev2010.zh-en.en.xml\n",
      "zh-en/IWSLT15.TED.dev2010.zh-en.zh.xml\n",
      "zh-en/IWSLT15.TED.tst2010.zh-en.en.xml\n",
      "zh-en/IWSLT15.TED.tst2010.zh-en.zh.xml\n",
      "zh-en/IWSLT15.TED.tst2011.zh-en.en.xml\n",
      "zh-en/IWSLT15.TED.tst2011.zh-en.zh.xml\n",
      "zh-en/IWSLT15.TED.tst2012.zh-en.en.xml\n",
      "zh-en/IWSLT15.TED.tst2012.zh-en.zh.xml\n",
      "zh-en/IWSLT15.TED.tst2013.zh-en.en.xml\n",
      "zh-en/IWSLT15.TED.tst2013.zh-en.zh.xml\n",
      "zh-en/README\n",
      "zh-en/train.en\n",
      "zh-en/train.tags.zh-en.en\n",
      "zh-en/train.tags.zh-en.zh\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf 2015-01/texts/zh/en/zh-en.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "en_dir='zh-en/train.tags.zh-en.en'\n",
    "zn_dir='zh-en/train.tags.zh-en.zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_out_html(filename1,filename2):\n",
    "\tf1 = open(filename1,'r')\n",
    "\tf2 = open(filename2,'r')\n",
    "\n",
    "\tdata1 = f1.readlines()\n",
    "\tdata2 = f2.readlines()\n",
    "\tassert len(data1)==len(data2)#用codecs会导致报错不知道为什么\n",
    "\tfw1 = open(filename1+\".txt\",'w')\n",
    "\tfw2 = open(filename2+\".txt\",'w')\n",
    "\n",
    "\tfor line1,line2 in tqdm(zip(data1,data2)):\n",
    "\t\tline1 = line1.strip()\n",
    "\t\tline2 = line2.strip()\n",
    "\t\tif line1 and line2:\n",
    "\t\t\tif '<' not in line1 and '>' not in line1 and '<' not in line2 and '>' not in line2:\n",
    "\t\t\t\tfw1.write(line1+\"\\n\")\n",
    "\t\t\t\tfw2.write(line2+\"\\n\")\n",
    "\tfw1.close()\n",
    "\tf1.close()\n",
    "\tfw2.close()\n",
    "\tf2.close()\n",
    "\n",
    "\treturn filename1+\".txt\",filename2+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "223685it [00:00, 688420.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('zh-en/train.tags.zh-en.en.txt', 'zh-en/train.tags.zh-en.zh.txt')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_out_html(en_dir,zn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_source_dev = ET.parse('zh-en/IWSLT15.TED.dev2010.zh-en.zh.xml')\n",
    "tree_source_dev = [seg.text for seg in tree_source_dev.iter('seg')]\n",
    "\n",
    "tree_target_dev = ET.parse('zh-en/IWSLT15.TED.dev2010.zh-en.en.xml')\n",
    "tree_target_dev = [seg.text for seg in tree_target_dev.iter('seg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 对我来说 在世界各地旅行 和从事人类学研究的生涯中 最大的乐趣之一莫过于 体验那些没有忘记传统的族群的生活 沐浴在微风中 触摸被雨水冲洗得晶莹光亮的石头 尝着苦叶的味道 你能感受到他们的历史 ', ' 在萨满教的传说中 老虎要跨越银河 因纽特老人的神话仍然引起后人的共鸣 或者在喜马拉雅山 佛教徒还在追随法门 这让我们想起人类学的核心揭示 它的思想要义是 我们生活的世界 不是存在于一个绝对的意识之中 而只是一个现实模型 只是一种适应性选择的结果 我们的祖先在很多世代以前就成功地做出了这种选择 ']\n",
      "[' You know, one of the intense pleasures of travel and one of the delights of ethnographic research is the opportunity to live amongst those who have not forgotten the old ways, who still feel their past in the wind, touch it in stones polished by rain, taste it in the bitter leaves of plants. ', ' Just to know that Jaguar shamans still journey beyond the Milky Way, or the myths of the Inuit elders still resonate with meaning, or that in the Himalaya, the Buddhists still pursue the breath of the Dharma, is to really remember the central revelation of anthropology, and that is the idea that the world in which we live does not exist in some absolute sense, but is just one model of reality, the consequence of one particular set of adaptive choices that our lineage made, albeit successfully, many generations ago. ']\n"
     ]
    }
   ],
   "source": [
    "print(tree_source_dev[:2])\n",
    "print(tree_target_dev[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('dev_cn.txt','w') as f:\n",
    "    for item in tree_source_dev:\n",
    "        f.write(item+'\\n')\n",
    "\n",
    "with open('dev_en.txt','w') as f:\n",
    "    for item in tree_target_dev:\n",
    "        f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tree_source_test = ET.parse('zh-en/IWSLT15.TED.tst2011.zh-en.zh.xml')\n",
    "tree_source_test = [seg.text for seg in tree_source_test.iter('seg')]\n",
    "\n",
    "tree_target_test = ET.parse('zh-en/IWSLT15.TED.tst2011.zh-en.en.xml')\n",
    "tree_target_test = [seg.text for seg in tree_target_test.iter('seg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('test_cn.txt','w') as f:\n",
    "    for item in tree_source_test:\n",
    "        f.write(item+'\\n')\n",
    "\n",
    "with open('test_en.txt','w') as f:\n",
    "    for item in tree_target_test:\n",
    "        f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 数据部分\n",
    "\n",
    "### 3.2.1  数据集介绍\n",
    "\n",
    "数据集使用的是IWSLT 2015，数据集的下载地址为： https://wit3.fbk.eu/2015-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2.2 数据预处理\n",
    "中文需要Jieba+BPE，英文需要BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 中文Jieba分词\n",
    "def jieba_cut(in_file,out_file):\n",
    "    out_f = open(out_file,'w',encoding='utf8')\n",
    "    with open(in_file,'r',encoding='utf8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            cut_line = ' '.join(jieba.cut(line))\n",
    "            out_f.write(cut_line+'\\n')\n",
    "    out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zn_dir='zh-en/train.tags.zh-en.zh.txt'\n",
    "cut_zn_dir='zh-en/train.tags.zh-en.zh.cut.txt'\n",
    "jieba_cut(zn_dir,cut_zn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zn_dir='dev_cn.txt'\n",
    "cut_zn_dir='dev_cn.cut.txt'\n",
    "jieba_cut(zn_dir,cut_zn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zn_dir='dev_cn.txt'\n",
    "cut_zn_dir='dev_cn.cut.txt'\n",
    "jieba_cut(zn_dir,cut_zn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zn_dir='test_cn.txt'\n",
    "cut_zn_dir='test_cn.cut.txt'\n",
    "jieba_cut(zn_dir,cut_zn_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 BPE分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3.1 bpe学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate the training data\n"
     ]
    }
   ],
   "source": [
    "print('generate the training data')\n",
    "!subword-nmt learn-bpe -s 32000 < zh-en/train.tags.zh-en.zh.cut.txt > zh-en/bpe.ch.32000\n",
    "!subword-nmt learn-bpe -s 32000 < zh-en/train.tags.zh-en.en.txt > zh-en/bpe.en.32000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3.2 bpe分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!subword-nmt apply-bpe -c zh-en/bpe.ch.32000 < zh-en/train.tags.zh-en.zh.cut.txt > zh-en/train.ch.bpe\n",
    "!subword-nmt apply-bpe -c zh-en/bpe.ch.32000 < dev_cn.cut.txt > zh-en/dev.ch.bpe\n",
    "!subword-nmt apply-bpe -c zh-en/bpe.ch.32000 < test_cn.cut.txt > zh-en/test.ch.bpe\n",
    "!subword-nmt apply-bpe -c zh-en/bpe.en.32000 < zh-en/train.tags.zh-en.en.txt > zh-en/train.en.bpe\n",
    "!subword-nmt apply-bpe -c zh-en/bpe.en.32000 < dev_en.txt > zh-en/dev.en.bpe\n",
    "!subword-nmt apply-bpe -c zh-en/bpe.en.32000 < test_en.txt > zh-en/test.en.bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!subword-nmt  get-vocab -i zh-en/train.ch.bpe -o zh-en/temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "special_token=['<s>','<e>','<unk>']\n",
    "cn_vocab=[]\n",
    "with open('zh-en/temp') as f:\n",
    "    for item in f.readlines():\n",
    "        words=item.strip().split()\n",
    "        cn_vocab.append(words[0])\n",
    "\n",
    "with open('zh-en/vocab.ch.src','w') as f:\n",
    "    for item in special_token:\n",
    "        f.write(item+'\\n')\n",
    "    for item in cn_vocab:\n",
    "        f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!subword-nmt  get-vocab -i zh-en/train.en.bpe -o zh-en/temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng_vocab=[]\n",
    "with open('zh-en/temp') as f:\n",
    "    for item in f.readlines():\n",
    "        words=item.strip().split()\n",
    "        eng_vocab.append(words[0])\n",
    "        \n",
    "with open('zh-en/vocab.en.tgt','w') as f:\n",
    "    for item in special_token:\n",
    "        f.write(item+'\\n')\n",
    "    for item in eng_vocab:\n",
    "        f.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cn_data=[]\n",
    "with open('zh-en/train.ch.bpe') as f:\n",
    "    for item in f.readlines():\n",
    "        words=item.strip()\n",
    "        cn_data.append(words)\n",
    "en_data=[]\n",
    "with open('zh-en/train.en.bpe') as f:\n",
    "    for item in f.readlines():\n",
    "        words=item.strip()\n",
    "        en_data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['大卫 . 盖@@ 罗 ： 这位 是 比尔 . 兰@@ 格 ， 我 是 大卫 . 盖@@ 罗 。', '我们 将 用 一些 影片 来 讲述 一些 深海 里 的 故事 。', '我们 这有 不少 精彩 的 泰坦尼克 的 影片 ， 可惜 您 今天 看不到 。', '泰坦尼克号 是 拿 了 不少 票房 冠军 但 事实上 它 并 不是 关于 海洋 的 最 刺激 的 故事 。', '原因 在于 我们 一直 没 把 海洋 当 回@@ 事儿 。', '大家 想想 ， 海洋 占 了 地球 面积 的 75 ％ 。', '地球 的 大部分 都 是 海水 。', '海洋 的 平均 深度 是 两英里', '当 你 站 在 海滩 上 或是 当 你 看到 海洋 里 的 图像 ， 当 你 看着 这么 一 大片 蓝色 ， 它@@ 泛 着 光 ， 不断 地 变动 着 ， 一会儿 是 海浪 ， 一会儿 是 波@@ 涛 ， 一会儿 又 涨潮 ， 你 却 不 知道 它 里面 到底 有些 什么 。', '其实 地球 上 最长 的 山脉 都 在 海洋 里 。']\n",
      "[\"This is Bill Lang@@ e. I'm Dave Gal@@ lo.\", \"And we're going to tell you some stories from the sea here in video.\", \"We've got some of the most incredible video of Tit@@ anic that's ever been seen, and we're not going to show you any of it.\", \"The truth of the matter is that the Tit@@ anic -- even though it's breaking all sorts of box office records -- it's not the most exciting story from the sea.\", 'And the problem, I think, is that we take the ocean for granted.', 'When you think about it, the oceans are 75 percent of the planet.', 'Most of the planet is ocean water.', 'The average depth is about two miles.', \"Part of the problem, I think, is we stand at the beach, or we see images like this of the ocean, and you look out at this great big blue exp@@ ans@@ e, and it's sh@@ immer@@ ing and it's moving and there's waves and there's surf and there's tid@@ es, but you have no idea for what lies in there.\", 'And in the oceans, there are the longest mountain ranges on the planet.']\n"
     ]
    }
   ],
   "source": [
    "print(cn_data[:10])\n",
    "print(en_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.5 构造dataloader\n",
    "\n",
    "下面的`create_data_loader`函数用于创建训练集、验证集所需要的`DataLoader`对象,  \n",
    "`create_infer_loader`函数用于创建预测集所需要的`DataLoader`对象，   \n",
    "`DataLoader`对象用于产生一个个batch的数据。下面对函数中调用的`paddlenlp`内置函数作简单说明：\n",
    "* `paddlenlp.data.Vocab.load_vocabulary`：Vocab词表类，集合了一系列文本token与ids之间映射的一系列方法，支持从文件、字典、json等一系方式构建词表\n",
    "* `paddlenlp.datasets.load_dataset`：从本地文件创建数据集时，推荐根据本地数据集的格式给出读取function并传入 load_dataset() 中创建数据集\n",
    "* `paddlenlp.data.sampler.SamplerHelper`：构建用于DataLoader的可迭代采样器，它包含shuffle、sort、batch、shard等一系列方法，方便用户灵活使用\n",
    "* `paddlenlp.data.Pad`：padding 操作\n",
    "\n",
    "具体可参考[PaddleNLP的文档](https://paddlenlp.readthedocs.io/zh/latest/data_prepare/dataset_self_defined.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def min_max_filer(data, max_len, min_len=0):\n",
    "    # 1 for special tokens.\n",
    "    data_min_len = min(len(data[0]), len(data[1])) + 1\n",
    "    data_max_len = max(len(data[0]), len(data[1])) + 1\n",
    "    return (data_min_len >= min_len) and (data_max_len <= max_len)\n",
    "\n",
    "\n",
    "def read(src_path, tgt_path, is_predict=False):\n",
    "    if is_predict:\n",
    "        with open(src_path, 'r', encoding='utf8') as src_f:\n",
    "            for src_line in src_f.readlines():\n",
    "                src_line = src_line.strip()\n",
    "                if not src_line:\n",
    "                    continue\n",
    "                yield {'src':src_line, 'tgt':''}\n",
    "    else:\n",
    "        with open(src_path, 'r', encoding='utf8') as src_f, open(tgt_path, 'r', encoding='utf8') as tgt_f:\n",
    "            for src_line, tgt_line in zip(src_f.readlines(), tgt_f.readlines()):\n",
    "                src_line = src_line.strip()\n",
    "                if not src_line:\n",
    "                    continue\n",
    "                tgt_line = tgt_line.strip()\n",
    "                if not tgt_line:\n",
    "                    continue\n",
    "                yield {'src':src_line, 'tgt':tgt_line}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建训练集、验证集的dataloader\n",
    "def create_data_loader(args):\n",
    "    train_dataset = load_dataset(read, src_path=args.training_file.split(',')[0], tgt_path=args.training_file.split(',')[1], lazy=False)\n",
    "    dev_dataset = load_dataset(read, src_path=args.training_file.split(',')[0], tgt_path=args.training_file.split(',')[1], lazy=False)\n",
    "    print('load src vocab')\n",
    "    print( args.src_vocab_fpath)\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    print('load trg vocab')\n",
    "    print(args.trg_vocab_fpath)\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    print('padding')\n",
    "    padding_vocab = (\n",
    "        lambda x: (x + args.pad_factor - 1) // args.pad_factor * args.pad_factor\n",
    "    )\n",
    "    args.src_vocab_size = padding_vocab(len(src_vocab))\n",
    "    args.trg_vocab_size = padding_vocab(len(trg_vocab))\n",
    "    print('convert example')\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        target = sample['tgt'].split()\n",
    "\n",
    "        source = src_vocab.to_indices(source)\n",
    "        target = trg_vocab.to_indices(target)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    data_loaders = [(None)] * 2\n",
    "    print('dataset loop')\n",
    "    for i, dataset in enumerate([train_dataset, dev_dataset]):\n",
    "        dataset = dataset.map(convert_samples, lazy=False).filter(\n",
    "            partial(\n",
    "                min_max_filer, max_len=args.max_length))\n",
    "\n",
    "        sampler = SamplerHelper(dataset)\n",
    "\n",
    "        if args.sort_type == SortType.GLOBAL:\n",
    "            src_key = (lambda x, data_source: len(data_source[x][0]) + 1)\n",
    "            trg_key = (lambda x, data_source: len(data_source[x][1]) + 1)\n",
    "            # Sort twice\n",
    "            sampler = sampler.sort(key=trg_key).sort(key=src_key)\n",
    "        else:\n",
    "            if args.shuffle:\n",
    "                sampler = sampler.shuffle(seed=args.shuffle_seed)\n",
    "            max_key = (lambda x, data_source: max(len(data_source[x][0]), len(data_source[x][1])) + 1)\n",
    "            if args.sort_type == SortType.POOL:\n",
    "                sampler = sampler.sort(key=max_key, buffer_size=args.pool_size)\n",
    "\n",
    "        batch_size_fn = lambda new, count, sofar, data_source: max(sofar, len(data_source[new][0]) + 1,\n",
    "                                                                   len(data_source[new][1]) + 1)\n",
    "        batch_sampler = sampler.batch(\n",
    "            batch_size=args.batch_size,\n",
    "            drop_last=False,\n",
    "            batch_size_fn=batch_size_fn,\n",
    "            key=lambda size_so_far, minibatch_len: size_so_far * minibatch_len)\n",
    "\n",
    "        if args.shuffle_batch:\n",
    "            batch_sampler = batch_sampler.shuffle(seed=args.shuffle_seed)\n",
    "\n",
    "        if i == 0:\n",
    "            batch_sampler = batch_sampler.shard()\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_sampler=batch_sampler,\n",
    "            collate_fn=partial(\n",
    "                prepare_train_input,\n",
    "                bos_idx=args.bos_idx,\n",
    "                eos_idx=args.eos_idx,\n",
    "                pad_idx=args.bos_idx),\n",
    "            num_workers=2,\n",
    "            return_list=True)\n",
    "        data_loaders[i] = (data_loader)\n",
    "    return data_loaders\n",
    "\n",
    "class SortType(object):\n",
    "    GLOBAL = 'global'\n",
    "    POOL = 'pool'\n",
    "    NONE = \"none\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.6  模型训练\n",
    "PaddleNLP提供Transformer API供调用：\n",
    "* `paddlenlp.transformers.TransformerModel`：Transformer模型的实现\n",
    "* `paddlenlp.transformers.InferTransformerModel`：Transformer模型用于生成\n",
    "* `paddlenlp.transformers.CrossEntropyCriterion`：计算交叉熵损失\n",
    "* `paddlenlp.transformers.position_encoding_init`：Transformer 位置编码的初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "运行`do_train`函数，\n",
    "在`do_train`函数中，配置优化器、损失函数，以及评价指标（困惑度）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 4096,\n",
      " 'beam_size': 5,\n",
      " 'beta1': 0.9,\n",
      " 'beta2': 0.997,\n",
      " 'bos_idx': 0,\n",
      " 'd_inner_hid': 2048,\n",
      " 'd_model': 512,\n",
      " 'dropout': 0.1,\n",
      " 'eos_idx': 1,\n",
      " 'epoch': 30,\n",
      " 'eps': '1e-9',\n",
      " 'infer_batch_size': 32,\n",
      " 'inference_model_dir': '',\n",
      " 'init_from_checkpoint': '',\n",
      " 'init_from_params': '',\n",
      " 'init_from_pretrain_model': '',\n",
      " 'label_smooth_eps': 0.1,\n",
      " 'learning_rate': 2.0,\n",
      " 'max_length': 256,\n",
      " 'max_out_len': 256,\n",
      " 'n_best': 1,\n",
      " 'n_head': 8,\n",
      " 'n_layer': 6,\n",
      " 'output_file': 'predict.txt',\n",
      " 'pad_factor': 8,\n",
      " 'pool_size': 200000,\n",
      " 'predict_file': 'zh-en/test.ch.bpe',\n",
      " 'print_step': 100,\n",
      " 'random_seed': 'None',\n",
      " 'root': 'None',\n",
      " 'save_model': 'trained_models',\n",
      " 'save_step': 10000,\n",
      " 'shuffle': True,\n",
      " 'shuffle_batch': True,\n",
      " 'shuffle_seed': 128,\n",
      " 'sort_type': 'global',\n",
      " 'special_token': ['<s>', '<e>', '<unk>'],\n",
      " 'src_vocab_fpath': 'zh-en/vocab.ch.src',\n",
      " 'src_vocab_size': 10000,\n",
      " 'training_file': 'zh-en/train.ch.bpe,zh-en/train.en.bpe',\n",
      " 'trg_vocab_fpath': 'zh-en/vocab.en.tgt',\n",
      " 'trg_vocab_size': 10000,\n",
      " 'unk_idx': 2,\n",
      " 'use_gpu': True,\n",
      " 'validation_file': 'zh-en/dev.ch.bpe,zh-en/dev.en.bpe',\n",
      " 'warmup_steps': 8000,\n",
      " 'weight_sharing': False}\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "\n",
    "# 读入参数:这个配置文件需要在这里找：https://github.com/paddlepaddle/awesome-DeepLearning\n",
    "yaml_file = './transformer.base.yaml'\n",
    "with open(yaml_file, 'rt') as f:\n",
    "    args = AttrDict(yaml.safe_load(f))\n",
    "    pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zh-en/train.ch.bpe', 'zh-en/train.en.bpe']\n"
     ]
    }
   ],
   "source": [
    "print(args.training_file.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_train_input(insts, bos_idx, eos_idx, pad_idx):\n",
    "    \"\"\"\n",
    "    Put all padded data needed by training into a list.\n",
    "    \"\"\"\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad([inst[0] + [eos_idx] for inst in insts])\n",
    "    trg_word = word_pad([[bos_idx] + inst[1] for inst in insts])\n",
    "    lbl_word = np.expand_dims(\n",
    "        word_pad([inst[1] + [eos_idx] for inst in insts]), axis=2)\n",
    "\n",
    "    data_inputs = [src_word, trg_word, lbl_word]\n",
    "\n",
    "    return data_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load src vocab\n",
      "zh-en/vocab.ch.src\n",
      "load trg vocab\n",
      "zh-en/vocab.en.tgt\n",
      "padding\n",
      "convert example\n",
      "dataset loop\n"
     ]
    }
   ],
   "source": [
    " # Define data loader\n",
    "(train_loader), (eval_loader) = create_data_loader(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[363, 3], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[4249, 179 , 1   ],\n",
      "        [4249, 179 , 1   ],\n",
      "        [811 , 5   , 1   ],\n",
      "        ...,\n",
      "        [410 , 340 , 1   ],\n",
      "        [212 , 410 , 1   ],\n",
      "        [1927, 4   , 1   ]])\n",
      "Tensor(shape=[363, 11], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[0   , 726 , 70  , ..., 0   , 0   , 0   ],\n",
      "        [0   , 726 , 70  , ..., 0   , 0   , 0   ],\n",
      "        [0   , 194 , 12  , ..., 0   , 0   , 0   ],\n",
      "        ...,\n",
      "        [0   , 570 , 5989, ..., 7034, 7963, 0   ],\n",
      "        [0   , 31  , 585 , ..., 112 , 27  , 2366],\n",
      "        [0   , 85  , 141 , ..., 5   , 3   , 8065]])\n",
      "Tensor(shape=[363, 11, 1], dtype=int64, place=CUDAPinnedPlace, stop_gradient=True,\n",
      "       [[[726 ],\n",
      "         [70  ],\n",
      "         [26  ],\n",
      "         ...,\n",
      "         [0   ],\n",
      "         [0   ],\n",
      "         [0   ]],\n",
      "\n",
      "        [[726 ],\n",
      "         [70  ],\n",
      "         [26  ],\n",
      "         ...,\n",
      "         [0   ],\n",
      "         [0   ],\n",
      "         [0   ]],\n",
      "\n",
      "        [[194 ],\n",
      "         [12  ],\n",
      "         [50  ],\n",
      "         ...,\n",
      "         [0   ],\n",
      "         [0   ],\n",
      "         [0   ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[570 ],\n",
      "         [5989],\n",
      "         [58  ],\n",
      "         ...,\n",
      "         [7963],\n",
      "         [1   ],\n",
      "         [0   ]],\n",
      "\n",
      "        [[31  ],\n",
      "         [585 ],\n",
      "         [43  ],\n",
      "         ...,\n",
      "         [27  ],\n",
      "         [2366],\n",
      "         [1   ]],\n",
      "\n",
      "        [[85  ],\n",
      "         [141 ],\n",
      "         [32  ],\n",
      "         ...,\n",
      "         [3   ],\n",
      "         [8065],\n",
      "         [1   ]]])\n"
     ]
    }
   ],
   "source": [
    "for input_data in train_loader:\n",
    "    (src_word, trg_word, lbl_word) = input_data\n",
    "    print(src_word)\n",
    "    print(trg_word)\n",
    "    print(lbl_word)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_train(args,train_loader,eval_loader):\n",
    "    if args.use_gpu:\n",
    "        rank = dist.get_rank()\n",
    "        trainer_count = dist.get_world_size()\n",
    "    else:\n",
    "        rank = 0\n",
    "        trainer_count = 1\n",
    "        paddle.set_device(\"cpu\")\n",
    "\n",
    "    if trainer_count > 1:\n",
    "        dist.init_parallel_env()\n",
    "\n",
    "    # Set seed for CE\n",
    "    random_seed = eval(str(args.random_seed))\n",
    "    if random_seed is not None:\n",
    "        paddle.seed(random_seed)\n",
    "\n",
    "\n",
    "\n",
    "    # Define model\n",
    "    transformer = TransformerModel(\n",
    "        src_vocab_size=args.src_vocab_size,\n",
    "        trg_vocab_size=args.trg_vocab_size,\n",
    "        max_length=args.max_length + 1,\n",
    "        n_layer=args.n_layer,\n",
    "        n_head=args.n_head,\n",
    "        d_model=args.d_model,\n",
    "        d_inner_hid=args.d_inner_hid,\n",
    "        dropout=args.dropout,\n",
    "        weight_sharing=args.weight_sharing,\n",
    "        bos_id=args.bos_idx,\n",
    "        eos_id=args.eos_idx)\n",
    "\n",
    "    # Define loss\n",
    "    criterion = CrossEntropyCriterion(args.label_smooth_eps, args.bos_idx)\n",
    "\n",
    "    scheduler = paddle.optimizer.lr.NoamDecay(\n",
    "        args.d_model, args.warmup_steps, args.learning_rate, last_epoch=0)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = paddle.optimizer.Adam(\n",
    "        learning_rate=scheduler,\n",
    "        beta1=args.beta1,\n",
    "        beta2=args.beta2,\n",
    "        epsilon=float(args.eps),\n",
    "        parameters=transformer.parameters())\n",
    "\n",
    "    # Init from some checkpoint, to resume the previous training\n",
    "    if args.init_from_checkpoint:\n",
    "        model_dict = paddle.load(\n",
    "            os.path.join(args.init_from_checkpoint, \"transformer.pdparams\"))\n",
    "        opt_dict = paddle.load(\n",
    "            os.path.join(args.init_from_checkpoint, \"transformer.pdopt\"))\n",
    "        transformer.set_state_dict(model_dict)\n",
    "        optimizer.set_state_dict(opt_dict)\n",
    "        print(\"loaded from checkpoint.\")\n",
    "    # Init from some pretrain models, to better solve the current task\n",
    "    if args.init_from_pretrain_model:\n",
    "        model_dict = paddle.load(\n",
    "            os.path.join(args.init_from_pretrain_model, \"transformer.pdparams\"))\n",
    "        transformer.set_state_dict(model_dict)\n",
    "        print(\"loaded from pre-trained model.\")\n",
    "\n",
    "    if trainer_count > 1:\n",
    "        transformer = paddle.DataParallel(transformer)\n",
    "\n",
    "    # The best cross-entropy value with label smoothing\n",
    "    loss_normalizer = -(\n",
    "        (1. - args.label_smooth_eps) * np.log(\n",
    "            (1. - args.label_smooth_eps)) + args.label_smooth_eps *\n",
    "        np.log(args.label_smooth_eps / (args.trg_vocab_size - 1) + 1e-20))\n",
    "\n",
    "    ce_time = []\n",
    "    ce_ppl = []\n",
    "    step_idx = 0\n",
    "\n",
    "    # Train loop\n",
    "    for pass_id in range(args.epoch):\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        batch_id = 0\n",
    "        batch_start = time.time()\n",
    "        for input_data in train_loader:\n",
    "            (src_word, trg_word, lbl_word) = input_data\n",
    "\n",
    "            logits = transformer(src_word=src_word, trg_word=trg_word)\n",
    "\n",
    "            sum_cost, avg_cost, token_num = criterion(logits, lbl_word)\n",
    "\n",
    "            avg_cost.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            if step_idx % args.print_step == 0 and rank == 0:\n",
    "                total_avg_cost = avg_cost.numpy()\n",
    "\n",
    "                if step_idx == 0:\n",
    "                    logger.info(\n",
    "                        \"step_idx: %d, epoch: %d, batch: %d, avg loss: %f, \"\n",
    "                        \"normalized loss: %f, ppl: %f \" %\n",
    "                        (step_idx, pass_id, batch_id, total_avg_cost,\n",
    "                         total_avg_cost - loss_normalizer,\n",
    "                         np.exp([min(total_avg_cost, 100)])))\n",
    "                else:\n",
    "                    train_avg_batch_cost = args.print_step / (\n",
    "                        time.time() - batch_start)\n",
    "                    logger.info(\n",
    "                        \"step_idx: %d, epoch: %d, batch: %d, avg loss: %f, \"\n",
    "                        \"normalized loss: %f, ppl: %f, avg_speed: %.2f step/sec\"\n",
    "                        % (\n",
    "                            step_idx,\n",
    "                            pass_id,\n",
    "                            batch_id,\n",
    "                            total_avg_cost,\n",
    "                            total_avg_cost - loss_normalizer,\n",
    "                            np.exp([min(total_avg_cost, 100)]),\n",
    "                            train_avg_batch_cost, ))\n",
    "                batch_start = time.time()\n",
    "\n",
    "            if step_idx % args.save_step == 0 and step_idx != 0:\n",
    "                # Validation\n",
    "                transformer.eval()\n",
    "                total_sum_cost = 0\n",
    "                total_token_num = 0\n",
    "                with paddle.no_grad():\n",
    "                    for input_data in eval_loader:\n",
    "                        (src_word, trg_word, lbl_word) = input_data\n",
    "                        logits = transformer(\n",
    "                            src_word=src_word, trg_word=trg_word)\n",
    "                        sum_cost, avg_cost, token_num = criterion(logits,\n",
    "                                                                  lbl_word)\n",
    "                        total_sum_cost += sum_cost.numpy()\n",
    "                        total_token_num += token_num.numpy()\n",
    "                        total_avg_cost = total_sum_cost / total_token_num\n",
    "                    logger.info(\"validation, step_idx: %d, avg loss: %f, \"\n",
    "                                \"normalized loss: %f, ppl: %f\" %\n",
    "                                (step_idx, total_avg_cost,\n",
    "                                 total_avg_cost - loss_normalizer,\n",
    "                                 np.exp([min(total_avg_cost, 100)])))\n",
    "                transformer.train()\n",
    "\n",
    "                if args.save_model and rank == 0:\n",
    "                    model_dir = os.path.join(args.save_model,\n",
    "                                             \"step_\" + str(step_idx))\n",
    "                    if not os.path.exists(model_dir):\n",
    "                        os.makedirs(model_dir)\n",
    "                    paddle.save(transformer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "                    paddle.save(optimizer.state_dict(),\n",
    "                                os.path.join(model_dir, \"transformer.pdopt\"))\n",
    "                batch_start = time.time()\n",
    "            batch_id += 1\n",
    "            step_idx += 1\n",
    "            scheduler.step()\n",
    "\n",
    "        train_epoch_cost = time.time() - epoch_start\n",
    "        ce_time.append(train_epoch_cost)\n",
    "        logger.info(\"train epoch: %d, epoch_cost: %.5f s\" %\n",
    "                    (pass_id, train_epoch_cost))\n",
    "\n",
    "    if args.save_model and rank == 0:\n",
    "        model_dir = os.path.join(args.save_model, \"step_final\")\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        paddle.save(transformer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdparams\"))\n",
    "        paddle.save(optimizer.state_dict(),\n",
    "                    os.path.join(model_dir, \"transformer.pdopt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-06-01 15:58:16,462] [    INFO] - step_idx: 0, epoch: 0, batch: 0, avg loss: 10.387688, normalized loss: 9.025434, ppl: 32457.525391 \n",
      "[2023-06-01 15:58:32,820] [    INFO] - step_idx: 100, epoch: 0, batch: 100, avg loss: 9.871328, normalized loss: 8.509074, ppl: 19367.048828, avg_speed: 6.12 step/sec\n",
      "[2023-06-01 15:58:49,257] [    INFO] - step_idx: 200, epoch: 0, batch: 200, avg loss: 9.142629, normalized loss: 7.780375, ppl: 9345.297852, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 15:59:05,629] [    INFO] - step_idx: 300, epoch: 0, batch: 300, avg loss: 8.223158, normalized loss: 6.860904, ppl: 3726.250977, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 15:59:21,953] [    INFO] - step_idx: 400, epoch: 0, batch: 400, avg loss: 7.811851, normalized loss: 6.449597, ppl: 2469.697754, avg_speed: 6.13 step/sec\n",
      "[2023-06-01 15:59:38,406] [    INFO] - step_idx: 500, epoch: 0, batch: 500, avg loss: 7.672816, normalized loss: 6.310563, ppl: 2149.125488, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 15:59:54,836] [    INFO] - step_idx: 600, epoch: 0, batch: 600, avg loss: 7.104311, normalized loss: 5.742058, ppl: 1217.203735, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:00:11,360] [    INFO] - step_idx: 700, epoch: 0, batch: 700, avg loss: 7.404890, normalized loss: 6.042636, ppl: 1644.003296, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:00:27,884] [    INFO] - step_idx: 800, epoch: 0, batch: 800, avg loss: 6.772980, normalized loss: 5.410726, ppl: 873.911987, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:00:44,353] [    INFO] - step_idx: 900, epoch: 0, batch: 900, avg loss: 6.665082, normalized loss: 5.302829, ppl: 784.528198, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:01:00,867] [    INFO] - step_idx: 1000, epoch: 0, batch: 1000, avg loss: 6.624673, normalized loss: 5.262419, ppl: 753.457703, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:01:17,324] [    INFO] - step_idx: 1100, epoch: 0, batch: 1100, avg loss: 6.534575, normalized loss: 5.172321, ppl: 688.540710, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:01:23,959] [    INFO] - train epoch: 0, epoch_cost: 188.86051 s\n",
      "[2023-06-01 16:01:35,021] [    INFO] - step_idx: 1200, epoch: 1, batch: 59, avg loss: 6.653143, normalized loss: 5.290890, ppl: 775.217407, avg_speed: 9.04 step/sec\n",
      "[2023-06-01 16:01:51,718] [    INFO] - step_idx: 1300, epoch: 1, batch: 159, avg loss: 6.610692, normalized loss: 5.248438, ppl: 742.996582, avg_speed: 5.99 step/sec\n",
      "[2023-06-01 16:02:08,436] [    INFO] - step_idx: 1400, epoch: 1, batch: 259, avg loss: 6.338271, normalized loss: 4.976017, ppl: 565.816956, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:02:25,058] [    INFO] - step_idx: 1500, epoch: 1, batch: 359, avg loss: 6.241768, normalized loss: 4.879514, ppl: 513.765991, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:02:41,694] [    INFO] - step_idx: 1600, epoch: 1, batch: 459, avg loss: 6.652321, normalized loss: 5.290067, ppl: 774.579895, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:02:58,287] [    INFO] - step_idx: 1700, epoch: 1, batch: 559, avg loss: 5.878178, normalized loss: 4.515924, ppl: 357.157959, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:03:14,849] [    INFO] - step_idx: 1800, epoch: 1, batch: 659, avg loss: 5.406365, normalized loss: 4.044111, ppl: 222.820160, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:03:31,448] [    INFO] - step_idx: 1900, epoch: 1, batch: 759, avg loss: 5.723849, normalized loss: 4.361595, ppl: 306.080719, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:03:47,933] [    INFO] - step_idx: 2000, epoch: 1, batch: 859, avg loss: 5.850497, normalized loss: 4.488244, ppl: 347.407074, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:04:04,547] [    INFO] - step_idx: 2100, epoch: 1, batch: 959, avg loss: 5.726645, normalized loss: 4.364391, ppl: 306.937775, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:04:21,005] [    INFO] - step_idx: 2200, epoch: 1, batch: 1059, avg loss: 5.238719, normalized loss: 3.876466, ppl: 188.428650, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:04:34,454] [    INFO] - train epoch: 1, epoch_cost: 190.49124 s\n",
      "[2023-06-01 16:04:38,665] [    INFO] - step_idx: 2300, epoch: 2, batch: 18, avg loss: 5.825521, normalized loss: 4.463267, ppl: 338.837616, avg_speed: 23.77 step/sec\n",
      "[2023-06-01 16:04:55,236] [    INFO] - step_idx: 2400, epoch: 2, batch: 118, avg loss: 6.008330, normalized loss: 4.646076, ppl: 406.803345, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:05:11,684] [    INFO] - step_idx: 2500, epoch: 2, batch: 218, avg loss: 5.769575, normalized loss: 4.407321, ppl: 320.401550, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:05:28,190] [    INFO] - step_idx: 2600, epoch: 2, batch: 318, avg loss: 5.383914, normalized loss: 4.021660, ppl: 217.873260, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:05:44,699] [    INFO] - step_idx: 2700, epoch: 2, batch: 418, avg loss: 5.637146, normalized loss: 4.274892, ppl: 280.660431, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:06:01,234] [    INFO] - step_idx: 2800, epoch: 2, batch: 518, avg loss: 5.772513, normalized loss: 4.410260, ppl: 321.344391, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:06:17,915] [    INFO] - step_idx: 2900, epoch: 2, batch: 618, avg loss: 4.825069, normalized loss: 3.462816, ppl: 124.595131, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:06:34,490] [    INFO] - step_idx: 3000, epoch: 2, batch: 718, avg loss: 5.809721, normalized loss: 4.447468, ppl: 333.526245, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:06:50,961] [    INFO] - step_idx: 3100, epoch: 2, batch: 818, avg loss: 4.739800, normalized loss: 3.377546, ppl: 114.411308, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:07:07,340] [    INFO] - step_idx: 3200, epoch: 2, batch: 918, avg loss: 5.066761, normalized loss: 3.704507, ppl: 158.659607, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 16:07:24,073] [    INFO] - step_idx: 3300, epoch: 2, batch: 1018, avg loss: 4.466175, normalized loss: 3.103921, ppl: 87.023224, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:07:40,624] [    INFO] - step_idx: 3400, epoch: 2, batch: 1118, avg loss: 5.159753, normalized loss: 3.797500, ppl: 174.121490, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:07:44,336] [    INFO] - train epoch: 2, epoch_cost: 189.87828 s\n",
      "[2023-06-01 16:07:58,246] [    INFO] - step_idx: 3500, epoch: 3, batch: 77, avg loss: 4.557656, normalized loss: 3.195403, ppl: 95.359711, avg_speed: 7.19 step/sec\n",
      "[2023-06-01 16:08:14,870] [    INFO] - step_idx: 3600, epoch: 3, batch: 177, avg loss: 5.311883, normalized loss: 3.949629, ppl: 202.731598, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:08:31,609] [    INFO] - step_idx: 3700, epoch: 3, batch: 277, avg loss: 4.484073, normalized loss: 3.121819, ppl: 88.594765, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:08:48,434] [    INFO] - step_idx: 3800, epoch: 3, batch: 377, avg loss: 5.002399, normalized loss: 3.640145, ppl: 148.769623, avg_speed: 5.95 step/sec\n",
      "[2023-06-01 16:09:05,181] [    INFO] - step_idx: 3900, epoch: 3, batch: 477, avg loss: 4.631863, normalized loss: 3.269609, ppl: 102.705231, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:09:21,790] [    INFO] - step_idx: 4000, epoch: 3, batch: 577, avg loss: 4.747054, normalized loss: 3.384800, ppl: 115.244293, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:09:38,438] [    INFO] - step_idx: 4100, epoch: 3, batch: 677, avg loss: 4.492898, normalized loss: 3.130644, ppl: 89.380089, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:09:54,857] [    INFO] - step_idx: 4200, epoch: 3, batch: 777, avg loss: 4.968159, normalized loss: 3.605905, ppl: 143.761932, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:10:11,363] [    INFO] - step_idx: 4300, epoch: 3, batch: 877, avg loss: 4.542746, normalized loss: 3.180492, ppl: 93.948387, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:10:28,020] [    INFO] - step_idx: 4400, epoch: 3, batch: 977, avg loss: 4.776477, normalized loss: 3.414223, ppl: 118.685463, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:10:44,606] [    INFO] - step_idx: 4500, epoch: 3, batch: 1077, avg loss: 5.179595, normalized loss: 3.817341, ppl: 177.610870, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:10:55,065] [    INFO] - train epoch: 3, epoch_cost: 190.72593 s\n",
      "[2023-06-01 16:11:02,187] [    INFO] - step_idx: 4600, epoch: 4, batch: 36, avg loss: 4.123409, normalized loss: 2.761156, ppl: 61.769474, avg_speed: 14.05 step/sec\n",
      "[2023-06-01 16:11:18,579] [    INFO] - step_idx: 4700, epoch: 4, batch: 136, avg loss: 4.283256, normalized loss: 2.921002, ppl: 72.476044, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 16:11:35,075] [    INFO] - step_idx: 4800, epoch: 4, batch: 236, avg loss: 3.714365, normalized loss: 2.352111, ppl: 41.032505, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:11:51,501] [    INFO] - step_idx: 4900, epoch: 4, batch: 336, avg loss: 4.218897, normalized loss: 2.856643, ppl: 67.958473, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:12:08,022] [    INFO] - step_idx: 5000, epoch: 4, batch: 436, avg loss: 4.357408, normalized loss: 2.995154, ppl: 78.054520, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:12:24,604] [    INFO] - step_idx: 5100, epoch: 4, batch: 536, avg loss: 5.006316, normalized loss: 3.644063, ppl: 149.353531, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:12:41,201] [    INFO] - step_idx: 5200, epoch: 4, batch: 636, avg loss: 3.773802, normalized loss: 2.411549, ppl: 43.545319, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:12:57,966] [    INFO] - step_idx: 5300, epoch: 4, batch: 736, avg loss: 3.680235, normalized loss: 2.317982, ppl: 39.655727, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:13:14,587] [    INFO] - step_idx: 5400, epoch: 4, batch: 836, avg loss: 4.203827, normalized loss: 2.841574, ppl: 66.942055, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:13:31,173] [    INFO] - step_idx: 5500, epoch: 4, batch: 936, avg loss: 4.406787, normalized loss: 3.044534, ppl: 82.005592, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:13:47,798] [    INFO] - step_idx: 5600, epoch: 4, batch: 1036, avg loss: 5.172900, normalized loss: 3.810646, ppl: 176.425674, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:14:04,269] [    INFO] - step_idx: 5700, epoch: 4, batch: 1136, avg loss: 4.703427, normalized loss: 3.341174, ppl: 110.324646, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:14:04,953] [    INFO] - train epoch: 4, epoch_cost: 189.88506 s\n",
      "[2023-06-01 16:14:21,801] [    INFO] - step_idx: 5800, epoch: 5, batch: 95, avg loss: 4.444656, normalized loss: 3.082402, ppl: 85.170563, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 16:14:38,311] [    INFO] - step_idx: 5900, epoch: 5, batch: 195, avg loss: 4.444850, normalized loss: 3.082597, ppl: 85.187134, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:14:55,722] [    INFO] - step_idx: 6000, epoch: 5, batch: 295, avg loss: 4.003714, normalized loss: 2.641460, ppl: 54.801289, avg_speed: 5.74 step/sec\n",
      "[2023-06-01 16:15:13,268] [    INFO] - step_idx: 6100, epoch: 5, batch: 395, avg loss: 2.686135, normalized loss: 1.323881, ppl: 14.674842, avg_speed: 5.70 step/sec\n",
      "[2023-06-01 16:15:29,986] [    INFO] - step_idx: 6200, epoch: 5, batch: 495, avg loss: 4.563620, normalized loss: 3.201366, ppl: 95.930122, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:15:46,616] [    INFO] - step_idx: 6300, epoch: 5, batch: 595, avg loss: 4.010459, normalized loss: 2.648206, ppl: 55.172211, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:16:03,227] [    INFO] - step_idx: 6400, epoch: 5, batch: 695, avg loss: 3.785639, normalized loss: 2.423385, ppl: 44.063801, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:16:19,812] [    INFO] - step_idx: 6500, epoch: 5, batch: 795, avg loss: 3.762393, normalized loss: 2.400139, ppl: 43.051311, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:16:36,155] [    INFO] - step_idx: 6600, epoch: 5, batch: 895, avg loss: 4.287555, normalized loss: 2.925302, ppl: 72.788300, avg_speed: 6.12 step/sec\n",
      "[2023-06-01 16:16:52,579] [    INFO] - step_idx: 6700, epoch: 5, batch: 995, avg loss: 4.577862, normalized loss: 3.215608, ppl: 97.306099, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:17:09,208] [    INFO] - step_idx: 6800, epoch: 5, batch: 1095, avg loss: 5.118537, normalized loss: 3.756284, ppl: 167.090805, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:17:16,840] [    INFO] - train epoch: 5, epoch_cost: 191.88313 s\n",
      "[2023-06-01 16:17:27,165] [    INFO] - step_idx: 6900, epoch: 6, batch: 54, avg loss: 3.351044, normalized loss: 1.988790, ppl: 28.532497, avg_speed: 9.69 step/sec\n",
      "[2023-06-01 16:17:43,746] [    INFO] - step_idx: 7000, epoch: 6, batch: 154, avg loss: 3.534932, normalized loss: 2.172678, ppl: 34.292686, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:18:00,252] [    INFO] - step_idx: 7100, epoch: 6, batch: 254, avg loss: 3.689438, normalized loss: 2.327184, ppl: 40.022343, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:18:16,867] [    INFO] - step_idx: 7200, epoch: 6, batch: 354, avg loss: 3.885668, normalized loss: 2.523414, ppl: 48.699451, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:18:33,535] [    INFO] - step_idx: 7300, epoch: 6, batch: 454, avg loss: 4.263781, normalized loss: 2.901527, ppl: 71.078201, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:18:50,122] [    INFO] - step_idx: 7400, epoch: 6, batch: 554, avg loss: 4.083826, normalized loss: 2.721572, ppl: 59.372166, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:19:06,711] [    INFO] - step_idx: 7500, epoch: 6, batch: 654, avg loss: 4.196054, normalized loss: 2.833801, ppl: 66.423737, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:19:23,349] [    INFO] - step_idx: 7600, epoch: 6, batch: 754, avg loss: 3.261372, normalized loss: 1.899118, ppl: 26.085291, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:19:39,904] [    INFO] - step_idx: 7700, epoch: 6, batch: 854, avg loss: 3.404653, normalized loss: 2.042399, ppl: 30.103842, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:19:56,390] [    INFO] - step_idx: 7800, epoch: 6, batch: 954, avg loss: 4.273969, normalized loss: 2.911715, ppl: 71.806046, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:20:12,936] [    INFO] - step_idx: 7900, epoch: 6, batch: 1054, avg loss: 4.028414, normalized loss: 2.666160, ppl: 56.171741, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:20:27,259] [    INFO] - train epoch: 6, epoch_cost: 190.41549 s\n",
      "[2023-06-01 16:20:30,700] [    INFO] - step_idx: 8000, epoch: 7, batch: 13, avg loss: 3.878014, normalized loss: 2.515760, ppl: 48.328156, avg_speed: 29.09 step/sec\n",
      "[2023-06-01 16:20:47,204] [    INFO] - step_idx: 8100, epoch: 7, batch: 113, avg loss: 4.255102, normalized loss: 2.892848, ppl: 70.463982, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:21:03,751] [    INFO] - step_idx: 8200, epoch: 7, batch: 213, avg loss: 3.422037, normalized loss: 2.059783, ppl: 30.631752, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:21:20,100] [    INFO] - step_idx: 8300, epoch: 7, batch: 313, avg loss: 3.756138, normalized loss: 2.393884, ppl: 42.782864, avg_speed: 6.12 step/sec\n",
      "[2023-06-01 16:21:36,726] [    INFO] - step_idx: 8400, epoch: 7, batch: 413, avg loss: 4.063083, normalized loss: 2.700829, ppl: 58.153309, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:21:53,255] [    INFO] - step_idx: 8500, epoch: 7, batch: 513, avg loss: 3.366975, normalized loss: 2.004721, ppl: 28.990690, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:22:09,853] [    INFO] - step_idx: 8600, epoch: 7, batch: 613, avg loss: 3.473484, normalized loss: 2.111230, ppl: 32.248894, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:22:26,394] [    INFO] - step_idx: 8700, epoch: 7, batch: 713, avg loss: 3.833866, normalized loss: 2.471612, ppl: 46.240963, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:22:42,924] [    INFO] - step_idx: 8800, epoch: 7, batch: 813, avg loss: 3.893819, normalized loss: 2.531565, ppl: 49.098038, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:22:59,512] [    INFO] - step_idx: 8900, epoch: 7, batch: 913, avg loss: 3.897391, normalized loss: 2.535137, ppl: 49.273712, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:23:16,084] [    INFO] - step_idx: 9000, epoch: 7, batch: 1013, avg loss: 3.518525, normalized loss: 2.156271, ppl: 33.734627, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:23:32,741] [    INFO] - step_idx: 9100, epoch: 7, batch: 1113, avg loss: 3.743961, normalized loss: 2.381707, ppl: 42.265064, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:23:37,240] [    INFO] - train epoch: 7, epoch_cost: 189.97739 s\n",
      "[2023-06-01 16:23:50,400] [    INFO] - step_idx: 9200, epoch: 8, batch: 72, avg loss: 3.310840, normalized loss: 1.948586, ppl: 27.408127, avg_speed: 7.60 step/sec\n",
      "[2023-06-01 16:24:06,978] [    INFO] - step_idx: 9300, epoch: 8, batch: 172, avg loss: 3.370152, normalized loss: 2.007898, ppl: 29.082941, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:24:23,462] [    INFO] - step_idx: 9400, epoch: 8, batch: 272, avg loss: 3.661423, normalized loss: 2.299170, ppl: 38.916691, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:24:40,011] [    INFO] - step_idx: 9500, epoch: 8, batch: 372, avg loss: 3.007578, normalized loss: 1.645324, ppl: 20.238325, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:24:56,584] [    INFO] - step_idx: 9600, epoch: 8, batch: 472, avg loss: 3.789479, normalized loss: 2.427225, ppl: 44.233353, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:25:13,161] [    INFO] - step_idx: 9700, epoch: 8, batch: 572, avg loss: 3.684089, normalized loss: 2.321836, ppl: 39.808857, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:25:29,645] [    INFO] - step_idx: 9800, epoch: 8, batch: 672, avg loss: 3.534603, normalized loss: 2.172349, ppl: 34.281414, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:25:46,091] [    INFO] - step_idx: 9900, epoch: 8, batch: 772, avg loss: 3.790630, normalized loss: 2.428376, ppl: 44.284294, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:26:02,463] [    INFO] - step_idx: 10000, epoch: 8, batch: 872, avg loss: 3.071243, normalized loss: 1.708989, ppl: 21.568687, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 16:27:12,536] [    INFO] - validation, step_idx: 10000, avg loss: 3.054839, normalized loss: 1.692585, ppl: 21.217766\n",
      "[2023-06-01 16:27:39,218] [    INFO] - step_idx: 10100, epoch: 8, batch: 972, avg loss: 3.625132, normalized loss: 2.262878, ppl: 37.529690, avg_speed: 5.95 step/sec\n",
      "[2023-06-01 16:27:56,131] [    INFO] - step_idx: 10200, epoch: 8, batch: 1072, avg loss: 3.807944, normalized loss: 2.445690, ppl: 45.057709, avg_speed: 5.91 step/sec\n",
      "[2023-06-01 16:28:07,687] [    INFO] - train epoch: 8, epoch_cost: 270.44461 s\n",
      "[2023-06-01 16:28:14,308] [    INFO] - step_idx: 10300, epoch: 9, batch: 31, avg loss: 3.361374, normalized loss: 1.999120, ppl: 28.828764, avg_speed: 15.11 step/sec\n",
      "[2023-06-01 16:28:30,816] [    INFO] - step_idx: 10400, epoch: 9, batch: 131, avg loss: 3.371871, normalized loss: 2.009617, ppl: 29.132990, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:28:47,414] [    INFO] - step_idx: 10500, epoch: 9, batch: 231, avg loss: 3.320434, normalized loss: 1.958180, ppl: 27.672354, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:29:03,841] [    INFO] - step_idx: 10600, epoch: 9, batch: 331, avg loss: 3.209715, normalized loss: 1.847461, ppl: 24.772028, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:29:20,381] [    INFO] - step_idx: 10700, epoch: 9, batch: 431, avg loss: 3.125974, normalized loss: 1.763721, ppl: 22.782082, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:29:36,880] [    INFO] - step_idx: 10800, epoch: 9, batch: 531, avg loss: 3.216525, normalized loss: 1.854271, ppl: 24.941299, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:29:53,296] [    INFO] - step_idx: 10900, epoch: 9, batch: 631, avg loss: 3.033221, normalized loss: 1.670967, ppl: 20.764008, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:30:09,798] [    INFO] - step_idx: 11000, epoch: 9, batch: 731, avg loss: 3.580462, normalized loss: 2.218208, ppl: 35.890129, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:30:26,314] [    INFO] - step_idx: 11100, epoch: 9, batch: 831, avg loss: 3.584996, normalized loss: 2.222743, ppl: 36.053230, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:30:42,814] [    INFO] - step_idx: 11200, epoch: 9, batch: 931, avg loss: 3.245831, normalized loss: 1.883578, ppl: 25.683054, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:30:59,358] [    INFO] - step_idx: 11300, epoch: 9, batch: 1031, avg loss: 3.662442, normalized loss: 2.300189, ppl: 38.956367, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:31:15,956] [    INFO] - step_idx: 11400, epoch: 9, batch: 1131, avg loss: 3.481361, normalized loss: 2.119107, ppl: 32.503933, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:31:17,518] [    INFO] - train epoch: 9, epoch_cost: 189.82664 s\n",
      "[2023-06-01 16:31:33,660] [    INFO] - step_idx: 11500, epoch: 10, batch: 90, avg loss: 3.068587, normalized loss: 1.706334, ppl: 21.511492, avg_speed: 6.20 step/sec\n",
      "[2023-06-01 16:31:50,410] [    INFO] - step_idx: 11600, epoch: 10, batch: 190, avg loss: 3.033174, normalized loss: 1.670920, ppl: 20.763025, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:32:06,865] [    INFO] - step_idx: 11700, epoch: 10, batch: 290, avg loss: 3.182582, normalized loss: 1.820328, ppl: 24.108913, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:32:23,398] [    INFO] - step_idx: 11800, epoch: 10, batch: 390, avg loss: 3.164018, normalized loss: 1.801764, ppl: 23.665497, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:32:40,141] [    INFO] - step_idx: 11900, epoch: 10, batch: 490, avg loss: 2.282346, normalized loss: 0.920092, ppl: 9.799644, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:32:56,571] [    INFO] - step_idx: 12000, epoch: 10, batch: 590, avg loss: 3.451431, normalized loss: 2.089177, ppl: 31.545486, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:33:13,168] [    INFO] - step_idx: 12100, epoch: 10, batch: 690, avg loss: 3.233370, normalized loss: 1.871116, ppl: 25.364996, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:33:29,784] [    INFO] - step_idx: 12200, epoch: 10, batch: 790, avg loss: 3.494390, normalized loss: 2.132136, ppl: 32.930202, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:33:46,352] [    INFO] - step_idx: 12300, epoch: 10, batch: 890, avg loss: 2.906142, normalized loss: 1.543888, ppl: 18.286112, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:34:02,869] [    INFO] - step_idx: 12400, epoch: 10, batch: 990, avg loss: 2.991907, normalized loss: 1.629653, ppl: 19.923632, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:34:19,486] [    INFO] - step_idx: 12500, epoch: 10, batch: 1090, avg loss: 3.392295, normalized loss: 2.030041, ppl: 29.734118, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:34:27,788] [    INFO] - train epoch: 10, epoch_cost: 190.26630 s\n",
      "[2023-06-01 16:34:37,267] [    INFO] - step_idx: 12600, epoch: 11, batch: 49, avg loss: 2.874246, normalized loss: 1.511992, ppl: 17.712067, avg_speed: 10.55 step/sec\n",
      "[2023-06-01 16:34:54,261] [    INFO] - step_idx: 12700, epoch: 11, batch: 149, avg loss: 2.748201, normalized loss: 1.385947, ppl: 15.614517, avg_speed: 5.89 step/sec\n",
      "[2023-06-01 16:35:10,995] [    INFO] - step_idx: 12800, epoch: 11, batch: 249, avg loss: 2.961168, normalized loss: 1.598914, ppl: 19.320526, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:35:27,933] [    INFO] - step_idx: 12900, epoch: 11, batch: 349, avg loss: 2.608879, normalized loss: 1.246625, ppl: 13.583810, avg_speed: 5.90 step/sec\n",
      "[2023-06-01 16:35:44,701] [    INFO] - step_idx: 13000, epoch: 11, batch: 449, avg loss: 3.052044, normalized loss: 1.689790, ppl: 21.158546, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:36:01,451] [    INFO] - step_idx: 13100, epoch: 11, batch: 549, avg loss: 2.816518, normalized loss: 1.454264, ppl: 16.718536, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:36:17,983] [    INFO] - step_idx: 13200, epoch: 11, batch: 649, avg loss: 3.072450, normalized loss: 1.710196, ppl: 21.594746, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:36:34,614] [    INFO] - step_idx: 13300, epoch: 11, batch: 749, avg loss: 2.783448, normalized loss: 1.421194, ppl: 16.174700, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:36:51,090] [    INFO] - step_idx: 13400, epoch: 11, batch: 849, avg loss: 3.029408, normalized loss: 1.667155, ppl: 20.684994, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:37:08,174] [    INFO] - step_idx: 13500, epoch: 11, batch: 949, avg loss: 3.193519, normalized loss: 1.831265, ppl: 24.374039, avg_speed: 5.85 step/sec\n",
      "[2023-06-01 16:37:24,983] [    INFO] - step_idx: 13600, epoch: 11, batch: 1049, avg loss: 2.624675, normalized loss: 1.262421, ppl: 13.800082, avg_speed: 5.95 step/sec\n",
      "[2023-06-01 16:37:39,984] [    INFO] - train epoch: 11, epoch_cost: 192.19137 s\n",
      "[2023-06-01 16:37:42,569] [    INFO] - step_idx: 13700, epoch: 12, batch: 8, avg loss: 2.792423, normalized loss: 1.430169, ppl: 16.320522, avg_speed: 38.73 step/sec\n",
      "[2023-06-01 16:37:59,083] [    INFO] - step_idx: 13800, epoch: 12, batch: 108, avg loss: 2.666871, normalized loss: 1.304617, ppl: 14.394859, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:38:16,482] [    INFO] - step_idx: 13900, epoch: 12, batch: 208, avg loss: 2.808812, normalized loss: 1.446559, ppl: 16.590204, avg_speed: 5.75 step/sec\n",
      "[2023-06-01 16:38:33,345] [    INFO] - step_idx: 14000, epoch: 12, batch: 308, avg loss: 2.823956, normalized loss: 1.461702, ppl: 16.843348, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 16:38:49,991] [    INFO] - step_idx: 14100, epoch: 12, batch: 408, avg loss: 2.977514, normalized loss: 1.615260, ppl: 19.638933, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:39:06,427] [    INFO] - step_idx: 14200, epoch: 12, batch: 508, avg loss: 2.843844, normalized loss: 1.481591, ppl: 17.181692, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:39:22,860] [    INFO] - step_idx: 14300, epoch: 12, batch: 608, avg loss: 2.916875, normalized loss: 1.554622, ppl: 18.483442, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:39:39,291] [    INFO] - step_idx: 14400, epoch: 12, batch: 708, avg loss: 3.025920, normalized loss: 1.663667, ppl: 20.612968, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:39:55,843] [    INFO] - step_idx: 14500, epoch: 12, batch: 808, avg loss: 2.864675, normalized loss: 1.502421, ppl: 17.543356, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:40:12,512] [    INFO] - step_idx: 14600, epoch: 12, batch: 908, avg loss: 3.163793, normalized loss: 1.801540, ppl: 23.660173, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:40:29,385] [    INFO] - step_idx: 14700, epoch: 12, batch: 1008, avg loss: 2.702657, normalized loss: 1.340403, ppl: 14.919312, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 16:40:45,997] [    INFO] - step_idx: 14800, epoch: 12, batch: 1108, avg loss: 2.930831, normalized loss: 1.568577, ppl: 18.743204, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:40:51,351] [    INFO] - train epoch: 12, epoch_cost: 191.36383 s\n",
      "[2023-06-01 16:41:03,708] [    INFO] - step_idx: 14900, epoch: 13, batch: 67, avg loss: 2.732554, normalized loss: 1.370300, ppl: 15.372096, avg_speed: 8.10 step/sec\n",
      "[2023-06-01 16:41:20,277] [    INFO] - step_idx: 15000, epoch: 13, batch: 167, avg loss: 2.644791, normalized loss: 1.282537, ppl: 14.080498, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:41:36,788] [    INFO] - step_idx: 15100, epoch: 13, batch: 267, avg loss: 2.732357, normalized loss: 1.370103, ppl: 15.369066, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:41:53,289] [    INFO] - step_idx: 15200, epoch: 13, batch: 367, avg loss: 2.753124, normalized loss: 1.390870, ppl: 15.691581, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:42:09,832] [    INFO] - step_idx: 15300, epoch: 13, batch: 467, avg loss: 2.872483, normalized loss: 1.510229, ppl: 17.680866, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:42:26,485] [    INFO] - step_idx: 15400, epoch: 13, batch: 567, avg loss: 2.740192, normalized loss: 1.377938, ppl: 15.489962, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:42:43,048] [    INFO] - step_idx: 15500, epoch: 13, batch: 667, avg loss: 2.780452, normalized loss: 1.418198, ppl: 16.126305, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:42:59,607] [    INFO] - step_idx: 15600, epoch: 13, batch: 767, avg loss: 2.628820, normalized loss: 1.266566, ppl: 13.857408, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:43:16,233] [    INFO] - step_idx: 15700, epoch: 13, batch: 867, avg loss: 2.915938, normalized loss: 1.553684, ppl: 18.466124, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:43:32,879] [    INFO] - step_idx: 15800, epoch: 13, batch: 967, avg loss: 2.615115, normalized loss: 1.252861, ppl: 13.668787, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:43:49,476] [    INFO] - step_idx: 15900, epoch: 13, batch: 1067, avg loss: 2.665083, normalized loss: 1.302829, ppl: 14.369137, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:44:01,609] [    INFO] - train epoch: 13, epoch_cost: 190.25397 s\n",
      "[2023-06-01 16:44:07,157] [    INFO] - step_idx: 16000, epoch: 14, batch: 26, avg loss: 2.327190, normalized loss: 0.964936, ppl: 10.249103, avg_speed: 18.04 step/sec\n",
      "[2023-06-01 16:44:23,631] [    INFO] - step_idx: 16100, epoch: 14, batch: 126, avg loss: 2.483623, normalized loss: 1.121369, ppl: 11.984600, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:44:40,268] [    INFO] - step_idx: 16200, epoch: 14, batch: 226, avg loss: 2.406420, normalized loss: 1.044166, ppl: 11.094173, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:44:57,369] [    INFO] - step_idx: 16300, epoch: 14, batch: 326, avg loss: 2.573996, normalized loss: 1.211742, ppl: 13.118134, avg_speed: 5.85 step/sec\n",
      "[2023-06-01 16:45:14,374] [    INFO] - step_idx: 16400, epoch: 14, batch: 426, avg loss: 2.419474, normalized loss: 1.057220, ppl: 11.239942, avg_speed: 5.88 step/sec\n",
      "[2023-06-01 16:45:30,979] [    INFO] - step_idx: 16500, epoch: 14, batch: 526, avg loss: 2.656062, normalized loss: 1.293808, ppl: 14.240099, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:45:47,604] [    INFO] - step_idx: 16600, epoch: 14, batch: 626, avg loss: 2.661120, normalized loss: 1.298866, ppl: 14.312313, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:46:04,040] [    INFO] - step_idx: 16700, epoch: 14, batch: 726, avg loss: 2.827090, normalized loss: 1.464836, ppl: 16.896223, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:46:20,410] [    INFO] - step_idx: 16800, epoch: 14, batch: 826, avg loss: 2.907748, normalized loss: 1.545494, ppl: 18.315506, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 16:46:37,041] [    INFO] - step_idx: 16900, epoch: 14, batch: 926, avg loss: 2.730253, normalized loss: 1.368000, ppl: 15.336775, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 16:46:53,452] [    INFO] - step_idx: 17000, epoch: 14, batch: 1026, avg loss: 2.774620, normalized loss: 1.412366, ppl: 16.032536, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 16:47:09,952] [    INFO] - step_idx: 17100, epoch: 14, batch: 1126, avg loss: 2.790304, normalized loss: 1.428050, ppl: 16.285965, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:47:12,309] [    INFO] - train epoch: 14, epoch_cost: 190.69619 s\n",
      "[2023-06-01 16:47:27,470] [    INFO] - step_idx: 17200, epoch: 15, batch: 85, avg loss: 2.549527, normalized loss: 1.187274, ppl: 12.801053, avg_speed: 6.60 step/sec\n",
      "[2023-06-01 16:47:43,920] [    INFO] - step_idx: 17300, epoch: 15, batch: 185, avg loss: 2.215808, normalized loss: 0.853555, ppl: 9.168818, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 16:48:00,602] [    INFO] - step_idx: 17400, epoch: 15, batch: 285, avg loss: 2.677355, normalized loss: 1.315101, ppl: 14.546568, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:48:17,083] [    INFO] - step_idx: 17500, epoch: 15, batch: 385, avg loss: 2.620414, normalized loss: 1.258160, ppl: 13.741415, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:48:33,520] [    INFO] - step_idx: 17600, epoch: 15, batch: 485, avg loss: 2.472551, normalized loss: 1.110297, ppl: 11.852643, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:48:50,077] [    INFO] - step_idx: 17700, epoch: 15, batch: 585, avg loss: 2.663830, normalized loss: 1.301576, ppl: 14.351151, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:49:06,586] [    INFO] - step_idx: 17800, epoch: 15, batch: 685, avg loss: 2.525203, normalized loss: 1.162949, ppl: 12.493425, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:49:23,073] [    INFO] - step_idx: 17900, epoch: 15, batch: 785, avg loss: 2.735655, normalized loss: 1.373401, ppl: 15.419834, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:49:39,548] [    INFO] - step_idx: 18000, epoch: 15, batch: 885, avg loss: 2.661031, normalized loss: 1.298777, ppl: 14.311030, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:49:56,048] [    INFO] - step_idx: 18100, epoch: 15, batch: 985, avg loss: 2.533474, normalized loss: 1.171221, ppl: 12.597198, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:50:12,634] [    INFO] - step_idx: 18200, epoch: 15, batch: 1085, avg loss: 2.799631, normalized loss: 1.437378, ppl: 16.438585, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:50:21,785] [    INFO] - train epoch: 15, epoch_cost: 189.47167 s\n",
      "[2023-06-01 16:50:30,824] [    INFO] - step_idx: 18300, epoch: 16, batch: 44, avg loss: 2.466384, normalized loss: 1.104130, ppl: 11.779774, avg_speed: 11.07 step/sec\n",
      "[2023-06-01 16:50:48,314] [    INFO] - step_idx: 18400, epoch: 16, batch: 144, avg loss: 2.508592, normalized loss: 1.146338, ppl: 12.287619, avg_speed: 5.72 step/sec\n",
      "[2023-06-01 16:51:05,909] [    INFO] - step_idx: 18500, epoch: 16, batch: 244, avg loss: 2.280879, normalized loss: 0.918625, ppl: 9.785274, avg_speed: 5.68 step/sec\n",
      "[2023-06-01 16:51:22,910] [    INFO] - step_idx: 18600, epoch: 16, batch: 344, avg loss: 2.499282, normalized loss: 1.137029, ppl: 12.173754, avg_speed: 5.88 step/sec\n",
      "[2023-06-01 16:51:39,879] [    INFO] - step_idx: 18700, epoch: 16, batch: 444, avg loss: 2.607850, normalized loss: 1.245597, ppl: 13.569848, avg_speed: 5.90 step/sec\n",
      "[2023-06-01 16:51:56,933] [    INFO] - step_idx: 18800, epoch: 16, batch: 544, avg loss: 2.613685, normalized loss: 1.251431, ppl: 13.649258, avg_speed: 5.87 step/sec\n",
      "[2023-06-01 16:52:13,789] [    INFO] - step_idx: 18900, epoch: 16, batch: 644, avg loss: 2.514036, normalized loss: 1.151782, ppl: 12.354694, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 16:52:30,403] [    INFO] - step_idx: 19000, epoch: 16, batch: 744, avg loss: 2.425863, normalized loss: 1.063609, ppl: 11.311986, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:52:46,984] [    INFO] - step_idx: 19100, epoch: 16, batch: 844, avg loss: 2.655167, normalized loss: 1.292913, ppl: 14.227363, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:53:03,572] [    INFO] - step_idx: 19200, epoch: 16, batch: 944, avg loss: 2.651953, normalized loss: 1.289699, ppl: 14.181711, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:53:20,048] [    INFO] - step_idx: 19300, epoch: 16, batch: 1044, avg loss: 2.533484, normalized loss: 1.171230, ppl: 12.597313, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:53:36,297] [    INFO] - train epoch: 16, epoch_cost: 194.50756 s\n",
      "[2023-06-01 16:53:38,101] [    INFO] - step_idx: 19400, epoch: 17, batch: 3, avg loss: 2.422012, normalized loss: 1.059758, ppl: 11.268507, avg_speed: 55.58 step/sec\n",
      "[2023-06-01 16:53:54,763] [    INFO] - step_idx: 19500, epoch: 17, batch: 103, avg loss: 2.418387, normalized loss: 1.056134, ppl: 11.227738, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 16:54:11,342] [    INFO] - step_idx: 19600, epoch: 17, batch: 203, avg loss: 2.397107, normalized loss: 1.034853, ppl: 10.991331, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:54:27,829] [    INFO] - step_idx: 19700, epoch: 17, batch: 303, avg loss: 2.382594, normalized loss: 1.020341, ppl: 10.832971, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:54:44,397] [    INFO] - step_idx: 19800, epoch: 17, batch: 403, avg loss: 2.495419, normalized loss: 1.133165, ppl: 12.126816, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:55:01,024] [    INFO] - step_idx: 19900, epoch: 17, batch: 503, avg loss: 2.200521, normalized loss: 0.838267, ppl: 9.029715, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 16:55:17,499] [    INFO] - step_idx: 20000, epoch: 17, batch: 603, avg loss: 2.659840, normalized loss: 1.297586, ppl: 14.293997, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 16:56:28,493] [    INFO] - validation, step_idx: 20000, avg loss: 2.102488, normalized loss: 0.740234, ppl: 8.186513\n",
      "[2023-06-01 16:56:55,163] [    INFO] - step_idx: 20100, epoch: 17, batch: 703, avg loss: 2.620260, normalized loss: 1.258006, ppl: 13.739298, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 16:57:11,883] [    INFO] - step_idx: 20200, epoch: 17, batch: 803, avg loss: 2.556322, normalized loss: 1.194068, ppl: 12.888325, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 16:57:28,296] [    INFO] - step_idx: 20300, epoch: 17, batch: 903, avg loss: 2.403620, normalized loss: 1.041367, ppl: 11.063157, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:57:44,892] [    INFO] - step_idx: 20400, epoch: 17, batch: 1003, avg loss: 2.576181, normalized loss: 1.213927, ppl: 13.146837, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:58:01,440] [    INFO] - step_idx: 20500, epoch: 17, batch: 1103, avg loss: 2.385522, normalized loss: 1.023268, ppl: 10.864734, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 16:58:07,562] [    INFO] - train epoch: 17, epoch_cost: 271.26144 s\n",
      "[2023-06-01 16:58:19,039] [    INFO] - step_idx: 20600, epoch: 18, batch: 62, avg loss: 2.473132, normalized loss: 1.110878, ppl: 11.859534, avg_speed: 8.72 step/sec\n",
      "[2023-06-01 16:58:35,462] [    INFO] - step_idx: 20700, epoch: 18, batch: 162, avg loss: 2.300258, normalized loss: 0.938004, ppl: 9.976756, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 16:58:52,005] [    INFO] - step_idx: 20800, epoch: 18, batch: 262, avg loss: 2.376706, normalized loss: 1.014452, ppl: 10.769372, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 16:59:08,510] [    INFO] - step_idx: 20900, epoch: 18, batch: 362, avg loss: 2.382261, normalized loss: 1.020007, ppl: 10.829363, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 16:59:25,090] [    INFO] - step_idx: 21000, epoch: 18, batch: 462, avg loss: 2.407375, normalized loss: 1.045121, ppl: 11.104769, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:59:41,683] [    INFO] - step_idx: 21100, epoch: 18, batch: 562, avg loss: 2.193767, normalized loss: 0.831513, ppl: 8.968936, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 16:59:58,348] [    INFO] - step_idx: 21200, epoch: 18, batch: 662, avg loss: 2.532220, normalized loss: 1.169966, ppl: 12.581401, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 17:00:14,935] [    INFO] - step_idx: 21300, epoch: 18, batch: 762, avg loss: 2.307165, normalized loss: 0.944911, ppl: 10.045900, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:00:31,730] [    INFO] - step_idx: 21400, epoch: 18, batch: 862, avg loss: 2.553246, normalized loss: 1.190993, ppl: 12.848749, avg_speed: 5.96 step/sec\n",
      "[2023-06-01 17:00:48,689] [    INFO] - step_idx: 21500, epoch: 18, batch: 962, avg loss: 2.381320, normalized loss: 1.019066, ppl: 10.819175, avg_speed: 5.90 step/sec\n",
      "[2023-06-01 17:01:05,536] [    INFO] - step_idx: 21600, epoch: 18, batch: 1062, avg loss: 2.448786, normalized loss: 1.086532, ppl: 11.574281, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 17:01:18,643] [    INFO] - train epoch: 18, epoch_cost: 191.07742 s\n",
      "[2023-06-01 17:01:23,426] [    INFO] - step_idx: 21700, epoch: 19, batch: 21, avg loss: 2.342223, normalized loss: 0.979969, ppl: 10.404342, avg_speed: 20.93 step/sec\n",
      "[2023-06-01 17:01:40,030] [    INFO] - step_idx: 21800, epoch: 19, batch: 121, avg loss: 2.195377, normalized loss: 0.833123, ppl: 8.983384, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:01:56,482] [    INFO] - step_idx: 21900, epoch: 19, batch: 221, avg loss: 2.236132, normalized loss: 0.873878, ppl: 9.357067, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:02:12,987] [    INFO] - step_idx: 22000, epoch: 19, batch: 321, avg loss: 2.280047, normalized loss: 0.917793, ppl: 9.777142, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 17:02:29,551] [    INFO] - step_idx: 22100, epoch: 19, batch: 421, avg loss: 2.226218, normalized loss: 0.863964, ppl: 9.264756, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:02:45,990] [    INFO] - step_idx: 22200, epoch: 19, batch: 521, avg loss: 2.454742, normalized loss: 1.092488, ppl: 11.643432, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:03:02,392] [    INFO] - step_idx: 22300, epoch: 19, batch: 621, avg loss: 2.317429, normalized loss: 0.955175, ppl: 10.149548, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:03:18,972] [    INFO] - step_idx: 22400, epoch: 19, batch: 721, avg loss: 2.345145, normalized loss: 0.982891, ppl: 10.434786, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:03:35,718] [    INFO] - step_idx: 22500, epoch: 19, batch: 821, avg loss: 2.408684, normalized loss: 1.046431, ppl: 11.119324, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 17:03:52,210] [    INFO] - step_idx: 22600, epoch: 19, batch: 921, avg loss: 2.382435, normalized loss: 1.020181, ppl: 10.831241, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:04:08,762] [    INFO] - step_idx: 22700, epoch: 19, batch: 1021, avg loss: 2.526790, normalized loss: 1.164537, ppl: 12.513279, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:04:25,405] [    INFO] - step_idx: 22800, epoch: 19, batch: 1121, avg loss: 2.599189, normalized loss: 1.236935, ppl: 13.452818, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:04:28,652] [    INFO] - train epoch: 19, epoch_cost: 190.00511 s\n",
      "[2023-06-01 17:04:43,193] [    INFO] - step_idx: 22900, epoch: 20, batch: 80, avg loss: 1.911441, normalized loss: 0.549187, ppl: 6.762828, avg_speed: 6.88 step/sec\n",
      "[2023-06-01 17:04:59,624] [    INFO] - step_idx: 23000, epoch: 20, batch: 180, avg loss: 2.250292, normalized loss: 0.888038, ppl: 9.490505, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 17:05:16,275] [    INFO] - step_idx: 23100, epoch: 20, batch: 280, avg loss: 2.289926, normalized loss: 0.927672, ppl: 9.874208, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:05:33,342] [    INFO] - step_idx: 23200, epoch: 20, batch: 380, avg loss: 2.212671, normalized loss: 0.850417, ppl: 9.140096, avg_speed: 5.86 step/sec\n",
      "[2023-06-01 17:05:50,244] [    INFO] - step_idx: 23300, epoch: 20, batch: 480, avg loss: 2.173139, normalized loss: 0.810885, ppl: 8.785820, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:06:07,288] [    INFO] - step_idx: 23400, epoch: 20, batch: 580, avg loss: 2.341377, normalized loss: 0.979123, ppl: 10.395544, avg_speed: 5.87 step/sec\n",
      "[2023-06-01 17:06:24,157] [    INFO] - step_idx: 23500, epoch: 20, batch: 680, avg loss: 2.403177, normalized loss: 1.040923, ppl: 11.058249, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 17:06:40,826] [    INFO] - step_idx: 23600, epoch: 20, batch: 780, avg loss: 2.348085, normalized loss: 0.985831, ppl: 10.465510, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 17:06:58,202] [    INFO] - step_idx: 23700, epoch: 20, batch: 880, avg loss: 2.471088, normalized loss: 1.108834, ppl: 11.835316, avg_speed: 5.76 step/sec\n",
      "[2023-06-01 17:07:15,701] [    INFO] - step_idx: 23800, epoch: 20, batch: 980, avg loss: 2.343942, normalized loss: 0.981689, ppl: 10.422244, avg_speed: 5.72 step/sec\n",
      "[2023-06-01 17:07:33,278] [    INFO] - step_idx: 23900, epoch: 20, batch: 1080, avg loss: 2.526161, normalized loss: 1.163907, ppl: 12.505403, avg_speed: 5.69 step/sec\n",
      "[2023-06-01 17:07:43,508] [    INFO] - train epoch: 20, epoch_cost: 194.85301 s\n",
      "[2023-06-01 17:07:51,568] [    INFO] - step_idx: 24000, epoch: 21, batch: 39, avg loss: 2.190170, normalized loss: 0.827916, ppl: 8.936730, avg_speed: 12.41 step/sec\n",
      "[2023-06-01 17:08:08,460] [    INFO] - step_idx: 24100, epoch: 21, batch: 139, avg loss: 2.180351, normalized loss: 0.818097, ppl: 8.849408, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:08:24,885] [    INFO] - step_idx: 24200, epoch: 21, batch: 239, avg loss: 2.191397, normalized loss: 0.829144, ppl: 8.947708, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 17:08:41,452] [    INFO] - step_idx: 24300, epoch: 21, batch: 339, avg loss: 2.154390, normalized loss: 0.792136, ppl: 8.622627, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:08:58,191] [    INFO] - step_idx: 24400, epoch: 21, batch: 439, avg loss: 2.114170, normalized loss: 0.751916, ppl: 8.282705, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 17:09:15,107] [    INFO] - step_idx: 24500, epoch: 21, batch: 539, avg loss: 2.053179, normalized loss: 0.690925, ppl: 7.792636, avg_speed: 5.91 step/sec\n",
      "[2023-06-01 17:09:31,971] [    INFO] - step_idx: 24600, epoch: 21, batch: 639, avg loss: 2.217761, normalized loss: 0.855507, ppl: 9.186739, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 17:09:48,816] [    INFO] - step_idx: 24700, epoch: 21, batch: 739, avg loss: 2.020151, normalized loss: 0.657898, ppl: 7.539466, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 17:10:05,965] [    INFO] - step_idx: 24800, epoch: 21, batch: 839, avg loss: 2.360974, normalized loss: 0.998720, ppl: 10.601268, avg_speed: 5.83 step/sec\n",
      "[2023-06-01 17:10:22,859] [    INFO] - step_idx: 24900, epoch: 21, batch: 939, avg loss: 2.240404, normalized loss: 0.878150, ppl: 9.397125, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:10:39,501] [    INFO] - step_idx: 25000, epoch: 21, batch: 1039, avg loss: 2.140788, normalized loss: 0.778534, ppl: 8.506138, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:10:55,961] [    INFO] - step_idx: 25100, epoch: 21, batch: 1139, avg loss: 2.372118, normalized loss: 1.009864, ppl: 10.720074, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:10:56,160] [    INFO] - train epoch: 21, epoch_cost: 192.64764 s\n",
      "[2023-06-01 17:11:13,627] [    INFO] - step_idx: 25200, epoch: 22, batch: 98, avg loss: 2.141571, normalized loss: 0.779317, ppl: 8.512799, avg_speed: 5.73 step/sec\n",
      "[2023-06-01 17:11:30,037] [    INFO] - step_idx: 25300, epoch: 22, batch: 198, avg loss: 2.236697, normalized loss: 0.874443, ppl: 9.362356, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:11:46,602] [    INFO] - step_idx: 25400, epoch: 22, batch: 298, avg loss: 2.150049, normalized loss: 0.787796, ppl: 8.585282, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:12:03,110] [    INFO] - step_idx: 25500, epoch: 22, batch: 398, avg loss: 1.998853, normalized loss: 0.636600, ppl: 7.380589, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 17:12:20,016] [    INFO] - step_idx: 25600, epoch: 22, batch: 498, avg loss: 2.251275, normalized loss: 0.889021, ppl: 9.499837, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:12:36,748] [    INFO] - step_idx: 25700, epoch: 22, batch: 598, avg loss: 2.179613, normalized loss: 0.817360, ppl: 8.842887, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 17:12:53,541] [    INFO] - step_idx: 25800, epoch: 22, batch: 698, avg loss: 2.243130, normalized loss: 0.880876, ppl: 9.422775, avg_speed: 5.96 step/sec\n",
      "[2023-06-01 17:13:10,224] [    INFO] - step_idx: 25900, epoch: 22, batch: 798, avg loss: 2.283085, normalized loss: 0.920831, ppl: 9.806888, avg_speed: 6.00 step/sec\n",
      "[2023-06-01 17:13:26,726] [    INFO] - step_idx: 26000, epoch: 22, batch: 898, avg loss: 2.187524, normalized loss: 0.825271, ppl: 8.913119, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 17:13:43,424] [    INFO] - step_idx: 26100, epoch: 22, batch: 998, avg loss: 2.229915, normalized loss: 0.867661, ppl: 9.299072, avg_speed: 5.99 step/sec\n",
      "[2023-06-01 17:14:00,220] [    INFO] - step_idx: 26200, epoch: 22, batch: 1098, avg loss: 2.231844, normalized loss: 0.869590, ppl: 9.317028, avg_speed: 5.95 step/sec\n",
      "[2023-06-01 17:14:07,386] [    INFO] - train epoch: 22, epoch_cost: 191.22329 s\n",
      "[2023-06-01 17:14:18,295] [    INFO] - step_idx: 26300, epoch: 23, batch: 57, avg loss: 2.109041, normalized loss: 0.746787, ppl: 8.240335, avg_speed: 9.17 step/sec\n",
      "[2023-06-01 17:14:35,200] [    INFO] - step_idx: 26400, epoch: 23, batch: 157, avg loss: 2.148503, normalized loss: 0.786249, ppl: 8.572013, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:14:51,946] [    INFO] - step_idx: 26500, epoch: 23, batch: 257, avg loss: 2.141183, normalized loss: 0.778929, ppl: 8.509498, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 17:15:08,337] [    INFO] - step_idx: 26600, epoch: 23, batch: 357, avg loss: 2.240865, normalized loss: 0.878611, ppl: 9.401460, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:15:24,961] [    INFO] - step_idx: 26700, epoch: 23, batch: 457, avg loss: 2.169128, normalized loss: 0.806874, ppl: 8.750649, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:15:41,515] [    INFO] - step_idx: 26800, epoch: 23, batch: 557, avg loss: 2.244048, normalized loss: 0.881794, ppl: 9.431431, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:15:57,940] [    INFO] - step_idx: 26900, epoch: 23, batch: 657, avg loss: 2.150509, normalized loss: 0.788255, ppl: 8.589231, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 17:16:14,414] [    INFO] - step_idx: 27000, epoch: 23, batch: 757, avg loss: 2.258629, normalized loss: 0.896375, ppl: 9.569959, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:16:31,203] [    INFO] - step_idx: 27100, epoch: 23, batch: 857, avg loss: 2.300646, normalized loss: 0.938392, ppl: 9.980628, avg_speed: 5.96 step/sec\n",
      "[2023-06-01 17:16:48,053] [    INFO] - step_idx: 27200, epoch: 23, batch: 957, avg loss: 2.199727, normalized loss: 0.837473, ppl: 9.022546, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 17:17:04,952] [    INFO] - step_idx: 27300, epoch: 23, batch: 1057, avg loss: 2.120598, normalized loss: 0.758344, ppl: 8.336119, avg_speed: 5.92 step/sec\n",
      "[2023-06-01 17:17:19,073] [    INFO] - train epoch: 23, epoch_cost: 191.68345 s\n",
      "[2023-06-01 17:17:23,227] [    INFO] - step_idx: 27400, epoch: 24, batch: 16, avg loss: 2.057733, normalized loss: 0.695479, ppl: 7.828202, avg_speed: 24.10 step/sec\n",
      "[2023-06-01 17:17:40,299] [    INFO] - step_idx: 27500, epoch: 24, batch: 116, avg loss: 2.099338, normalized loss: 0.737084, ppl: 8.160762, avg_speed: 5.86 step/sec\n",
      "[2023-06-01 17:17:57,281] [    INFO] - step_idx: 27600, epoch: 24, batch: 216, avg loss: 2.109269, normalized loss: 0.747015, ppl: 8.242214, avg_speed: 5.89 step/sec\n",
      "[2023-06-01 17:18:14,108] [    INFO] - step_idx: 27700, epoch: 24, batch: 316, avg loss: 2.140820, normalized loss: 0.778566, ppl: 8.506411, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 17:18:30,844] [    INFO] - step_idx: 27800, epoch: 24, batch: 416, avg loss: 2.078254, normalized loss: 0.716000, ppl: 7.990507, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 17:18:47,472] [    INFO] - step_idx: 27900, epoch: 24, batch: 516, avg loss: 2.034721, normalized loss: 0.672467, ppl: 7.650118, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:19:03,952] [    INFO] - step_idx: 28000, epoch: 24, batch: 616, avg loss: 2.059000, normalized loss: 0.696746, ppl: 7.838126, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:19:20,487] [    INFO] - step_idx: 28100, epoch: 24, batch: 716, avg loss: 2.268743, normalized loss: 0.906489, ppl: 9.667239, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:19:37,131] [    INFO] - step_idx: 28200, epoch: 24, batch: 816, avg loss: 2.073475, normalized loss: 0.711221, ppl: 7.952410, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:19:53,769] [    INFO] - step_idx: 28300, epoch: 24, batch: 916, avg loss: 2.159698, normalized loss: 0.797444, ppl: 8.668521, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:20:10,310] [    INFO] - step_idx: 28400, epoch: 24, batch: 1016, avg loss: 2.176626, normalized loss: 0.814372, ppl: 8.816506, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:20:26,892] [    INFO] - step_idx: 28500, epoch: 24, batch: 1116, avg loss: 2.108811, normalized loss: 0.746557, ppl: 8.238441, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:20:30,932] [    INFO] - train epoch: 24, epoch_cost: 191.85468 s\n",
      "[2023-06-01 17:20:44,513] [    INFO] - step_idx: 28600, epoch: 25, batch: 75, avg loss: 2.192498, normalized loss: 0.830244, ppl: 8.957559, avg_speed: 7.37 step/sec\n",
      "[2023-06-01 17:21:01,163] [    INFO] - step_idx: 28700, epoch: 25, batch: 175, avg loss: 2.087566, normalized loss: 0.725312, ppl: 8.065261, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:21:17,553] [    INFO] - step_idx: 28800, epoch: 25, batch: 275, avg loss: 2.170583, normalized loss: 0.808330, ppl: 8.763395, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:21:34,072] [    INFO] - step_idx: 28900, epoch: 25, batch: 375, avg loss: 2.078932, normalized loss: 0.716678, ppl: 7.995923, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:21:50,466] [    INFO] - step_idx: 29000, epoch: 25, batch: 475, avg loss: 2.253259, normalized loss: 0.891005, ppl: 9.518703, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:22:07,103] [    INFO] - step_idx: 29100, epoch: 25, batch: 575, avg loss: 1.992731, normalized loss: 0.630478, ppl: 7.335543, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:22:23,673] [    INFO] - step_idx: 29200, epoch: 25, batch: 675, avg loss: 2.148916, normalized loss: 0.786662, ppl: 8.575553, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:22:40,290] [    INFO] - step_idx: 29300, epoch: 25, batch: 775, avg loss: 2.143599, normalized loss: 0.781345, ppl: 8.530082, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:22:56,741] [    INFO] - step_idx: 29400, epoch: 25, batch: 875, avg loss: 2.193191, normalized loss: 0.830937, ppl: 8.963771, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:23:13,497] [    INFO] - step_idx: 29500, epoch: 25, batch: 975, avg loss: 2.113591, normalized loss: 0.751337, ppl: 8.277912, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 17:23:30,358] [    INFO] - step_idx: 29600, epoch: 25, batch: 1075, avg loss: 2.084379, normalized loss: 0.722126, ppl: 8.039600, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 17:23:41,188] [    INFO] - train epoch: 25, epoch_cost: 190.25223 s\n",
      "[2023-06-01 17:23:48,127] [    INFO] - step_idx: 29700, epoch: 26, batch: 34, avg loss: 1.967425, normalized loss: 0.605172, ppl: 7.152239, avg_speed: 14.42 step/sec\n",
      "[2023-06-01 17:24:04,820] [    INFO] - step_idx: 29800, epoch: 26, batch: 134, avg loss: 1.977965, normalized loss: 0.615711, ppl: 7.228016, avg_speed: 5.99 step/sec\n",
      "[2023-06-01 17:24:21,276] [    INFO] - step_idx: 29900, epoch: 26, batch: 234, avg loss: 2.054224, normalized loss: 0.691970, ppl: 7.800784, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:24:37,884] [    INFO] - step_idx: 30000, epoch: 26, batch: 334, avg loss: 2.049639, normalized loss: 0.687385, ppl: 7.765094, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:25:48,688] [    INFO] - validation, step_idx: 30000, avg loss: 1.798626, normalized loss: 0.436372, ppl: 6.041338\n",
      "[2023-06-01 17:26:15,452] [    INFO] - step_idx: 30100, epoch: 26, batch: 434, avg loss: 2.118298, normalized loss: 0.756045, ppl: 8.316973, avg_speed: 5.93 step/sec\n",
      "[2023-06-01 17:26:32,020] [    INFO] - step_idx: 30200, epoch: 26, batch: 534, avg loss: 2.155324, normalized loss: 0.793070, ppl: 8.630686, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:26:48,368] [    INFO] - step_idx: 30300, epoch: 26, batch: 634, avg loss: 2.124870, normalized loss: 0.762616, ppl: 8.371805, avg_speed: 6.12 step/sec\n",
      "[2023-06-01 17:27:04,869] [    INFO] - step_idx: 30400, epoch: 26, batch: 734, avg loss: 2.094157, normalized loss: 0.731903, ppl: 8.118590, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 17:27:21,397] [    INFO] - step_idx: 30500, epoch: 26, batch: 834, avg loss: 2.062842, normalized loss: 0.700588, ppl: 7.868297, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:27:37,757] [    INFO] - step_idx: 30600, epoch: 26, batch: 934, avg loss: 1.923284, normalized loss: 0.561030, ppl: 6.843395, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 17:27:54,278] [    INFO] - step_idx: 30700, epoch: 26, batch: 1034, avg loss: 2.126050, normalized loss: 0.763796, ppl: 8.381696, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:28:10,655] [    INFO] - step_idx: 30800, epoch: 26, batch: 1134, avg loss: 2.152572, normalized loss: 0.790319, ppl: 8.606971, avg_speed: 6.11 step/sec\n",
      "[2023-06-01 17:28:11,683] [    INFO] - train epoch: 26, epoch_cost: 270.49179 s\n",
      "[2023-06-01 17:28:28,318] [    INFO] - step_idx: 30900, epoch: 27, batch: 93, avg loss: 1.959320, normalized loss: 0.597066, ppl: 7.094499, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:28:44,823] [    INFO] - step_idx: 31000, epoch: 27, batch: 193, avg loss: 2.081666, normalized loss: 0.719412, ppl: 8.017814, avg_speed: 6.06 step/sec\n",
      "[2023-06-01 17:29:01,349] [    INFO] - step_idx: 31100, epoch: 27, batch: 293, avg loss: 1.986227, normalized loss: 0.623973, ppl: 7.287984, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:29:17,955] [    INFO] - step_idx: 31200, epoch: 27, batch: 393, avg loss: 1.889046, normalized loss: 0.526793, ppl: 6.613060, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:29:34,490] [    INFO] - step_idx: 31300, epoch: 27, batch: 493, avg loss: 2.068162, normalized loss: 0.705908, ppl: 7.910271, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:29:51,022] [    INFO] - step_idx: 31400, epoch: 27, batch: 593, avg loss: 1.986796, normalized loss: 0.624542, ppl: 7.292132, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:30:07,586] [    INFO] - step_idx: 31500, epoch: 27, batch: 693, avg loss: 2.078018, normalized loss: 0.715764, ppl: 7.988621, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:30:24,304] [    INFO] - step_idx: 31600, epoch: 27, batch: 793, avg loss: 2.150276, normalized loss: 0.788023, ppl: 8.587232, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 17:30:40,910] [    INFO] - step_idx: 31700, epoch: 27, batch: 893, avg loss: 2.046602, normalized loss: 0.684348, ppl: 7.741550, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:30:57,399] [    INFO] - step_idx: 31800, epoch: 27, batch: 993, avg loss: 2.131753, normalized loss: 0.769499, ppl: 8.429633, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:31:13,862] [    INFO] - step_idx: 31900, epoch: 27, batch: 1093, avg loss: 2.191061, normalized loss: 0.828807, ppl: 8.944700, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:31:21,617] [    INFO] - train epoch: 27, epoch_cost: 189.92985 s\n",
      "[2023-06-01 17:31:31,535] [    INFO] - step_idx: 32000, epoch: 28, batch: 52, avg loss: 1.958618, normalized loss: 0.596364, ppl: 7.089521, avg_speed: 10.09 step/sec\n",
      "[2023-06-01 17:31:48,008] [    INFO] - step_idx: 32100, epoch: 28, batch: 152, avg loss: 1.910394, normalized loss: 0.548140, ppl: 6.755748, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:32:04,456] [    INFO] - step_idx: 32200, epoch: 28, batch: 252, avg loss: 2.171112, normalized loss: 0.808859, ppl: 8.768031, avg_speed: 6.08 step/sec\n",
      "[2023-06-01 17:32:20,993] [    INFO] - step_idx: 32300, epoch: 28, batch: 352, avg loss: 1.934130, normalized loss: 0.571877, ppl: 6.918026, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:32:37,484] [    INFO] - step_idx: 32400, epoch: 28, batch: 452, avg loss: 1.952066, normalized loss: 0.589812, ppl: 7.043224, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:32:54,335] [    INFO] - step_idx: 32500, epoch: 28, batch: 552, avg loss: 2.085422, normalized loss: 0.723168, ppl: 8.047988, avg_speed: 5.94 step/sec\n",
      "[2023-06-01 17:33:11,103] [    INFO] - step_idx: 32600, epoch: 28, batch: 652, avg loss: 2.041558, normalized loss: 0.679304, ppl: 7.702600, avg_speed: 5.97 step/sec\n",
      "[2023-06-01 17:33:27,651] [    INFO] - step_idx: 32700, epoch: 28, batch: 752, avg loss: 2.073317, normalized loss: 0.711063, ppl: 7.951154, avg_speed: 6.04 step/sec\n",
      "[2023-06-01 17:33:44,137] [    INFO] - step_idx: 32800, epoch: 28, batch: 852, avg loss: 1.879609, normalized loss: 0.517355, ppl: 6.550943, avg_speed: 6.07 step/sec\n",
      "[2023-06-01 17:34:00,729] [    INFO] - step_idx: 32900, epoch: 28, batch: 952, avg loss: 1.992102, normalized loss: 0.629848, ppl: 7.330925, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:34:17,344] [    INFO] - step_idx: 33000, epoch: 28, batch: 1052, avg loss: 2.132832, normalized loss: 0.770578, ppl: 8.438731, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:34:32,168] [    INFO] - train epoch: 28, epoch_cost: 190.54716 s\n",
      "[2023-06-01 17:34:35,260] [    INFO] - step_idx: 33100, epoch: 29, batch: 11, avg loss: 1.986810, normalized loss: 0.624557, ppl: 7.292237, avg_speed: 32.41 step/sec\n",
      "[2023-06-01 17:34:51,866] [    INFO] - step_idx: 33200, epoch: 29, batch: 111, avg loss: 1.877493, normalized loss: 0.515239, ppl: 6.537096, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:35:08,299] [    INFO] - step_idx: 33300, epoch: 29, batch: 211, avg loss: 1.998328, normalized loss: 0.636074, ppl: 7.376711, avg_speed: 6.09 step/sec\n",
      "[2023-06-01 17:35:24,696] [    INFO] - step_idx: 33400, epoch: 29, batch: 311, avg loss: 1.954258, normalized loss: 0.592004, ppl: 7.058678, avg_speed: 6.10 step/sec\n",
      "[2023-06-01 17:35:41,283] [    INFO] - step_idx: 33500, epoch: 29, batch: 411, avg loss: 2.011739, normalized loss: 0.649486, ppl: 7.476311, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:35:57,811] [    INFO] - step_idx: 33600, epoch: 29, batch: 511, avg loss: 1.912757, normalized loss: 0.550503, ppl: 6.771733, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:36:14,336] [    INFO] - step_idx: 33700, epoch: 29, batch: 611, avg loss: 1.843133, normalized loss: 0.480879, ppl: 6.316297, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:36:31,049] [    INFO] - step_idx: 33800, epoch: 29, batch: 711, avg loss: 1.934347, normalized loss: 0.572093, ppl: 6.919526, avg_speed: 5.98 step/sec\n",
      "[2023-06-01 17:36:47,582] [    INFO] - step_idx: 33900, epoch: 29, batch: 811, avg loss: 2.053962, normalized loss: 0.691708, ppl: 7.798738, avg_speed: 6.05 step/sec\n",
      "[2023-06-01 17:37:04,183] [    INFO] - step_idx: 34000, epoch: 29, batch: 911, avg loss: 1.945185, normalized loss: 0.582932, ppl: 6.994929, avg_speed: 6.03 step/sec\n",
      "[2023-06-01 17:37:20,789] [    INFO] - step_idx: 34100, epoch: 29, batch: 1011, avg loss: 1.973681, normalized loss: 0.611427, ppl: 7.197120, avg_speed: 6.02 step/sec\n",
      "[2023-06-01 17:37:37,434] [    INFO] - step_idx: 34200, epoch: 29, batch: 1111, avg loss: 2.142292, normalized loss: 0.780039, ppl: 8.518946, avg_speed: 6.01 step/sec\n",
      "[2023-06-01 17:37:42,258] [    INFO] - train epoch: 29, epoch_cost: 190.08435 s\n"
     ]
    }
   ],
   "source": [
    "print('training the model')\n",
    "do_train(args,train_loader,eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.7 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建测试集的dataloader\n",
    "def create_infer_loader(args):\n",
    "    dataset = load_dataset(read, src_path=args.predict_file, tgt_path=None, is_predict=True, lazy=False)\n",
    "\n",
    "    src_vocab = Vocab.load_vocabulary(\n",
    "        args.src_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "    trg_vocab = Vocab.load_vocabulary(\n",
    "        args.trg_vocab_fpath,\n",
    "        bos_token=args.special_token[0],\n",
    "        eos_token=args.special_token[1],\n",
    "        unk_token=args.special_token[2])\n",
    "\n",
    "    padding_vocab = (\n",
    "        lambda x: (x + args.pad_factor - 1) // args.pad_factor * args.pad_factor\n",
    "    )\n",
    "    args.src_vocab_size = padding_vocab(len(src_vocab))\n",
    "    args.trg_vocab_size = padding_vocab(len(trg_vocab))\n",
    "\n",
    "    def convert_samples(sample):\n",
    "        source = sample['src'].split()\n",
    "        target = sample['tgt'].split()\n",
    "\n",
    "        source = src_vocab.to_indices(source)\n",
    "        target = trg_vocab.to_indices(target)\n",
    "\n",
    "        return source, target\n",
    "\n",
    "    dataset = dataset.map(convert_samples, lazy=False)\n",
    "\n",
    "    batch_sampler = SamplerHelper(dataset).batch(\n",
    "        batch_size=args.infer_batch_size, drop_last=False)\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=partial(\n",
    "            prepare_infer_input,\n",
    "            bos_idx=args.bos_idx,\n",
    "            eos_idx=args.eos_idx,\n",
    "            pad_idx=args.bos_idx),\n",
    "        num_workers=2,\n",
    "        return_list=True)\n",
    "    return data_loader, trg_vocab.to_tokens\n",
    "\n",
    "\n",
    "def prepare_infer_input(insts, bos_idx, eos_idx, pad_idx):\n",
    "    \"\"\"\n",
    "    Put all padded data needed by beam search decoder into a list.\n",
    "    \"\"\"\n",
    "    word_pad = Pad(pad_idx)\n",
    "    src_word = word_pad([inst[0] + [eos_idx] for inst in insts])\n",
    "\n",
    "    return [src_word, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def post_process_seq(seq, bos_idx, eos_idx, output_bos=False, output_eos=False):\n",
    "    \"\"\"\n",
    "    Post-process the decoded sequence.\n",
    "    \"\"\"\n",
    "    eos_pos = len(seq) - 1\n",
    "    for i, idx in enumerate(seq):\n",
    "        if idx == eos_idx:\n",
    "            eos_pos = i\n",
    "            break\n",
    "    seq = [\n",
    "        idx for idx in seq[:eos_pos + 1]\n",
    "        if (output_bos or idx != bos_idx) and (output_eos or idx != eos_idx)\n",
    "    ]\n",
    "    return seq\n",
    "\n",
    "\n",
    "def do_predict(args):\n",
    "    if args.use_gpu:\n",
    "        place = \"gpu:0\"\n",
    "    else:\n",
    "        place = \"cpu\"\n",
    "\n",
    "    paddle.set_device(place)\n",
    "\n",
    "    # Define data loader\n",
    "    test_loader, to_tokens = create_infer_loader(args)\n",
    "\n",
    "    # Define model\n",
    "    transformer = InferTransformerModel(\n",
    "        src_vocab_size=args.src_vocab_size,\n",
    "        trg_vocab_size=args.trg_vocab_size,\n",
    "        max_length=args.max_length + 1,\n",
    "        n_layer=args.n_layer,\n",
    "        n_head=args.n_head,\n",
    "        d_model=args.d_model,\n",
    "        d_inner_hid=args.d_inner_hid,\n",
    "        dropout=args.dropout,\n",
    "        weight_sharing=args.weight_sharing,\n",
    "        bos_id=args.bos_idx,\n",
    "        eos_id=args.eos_idx,\n",
    "        beam_size=args.beam_size,\n",
    "        max_out_len=args.max_out_len)\n",
    "\n",
    "    # Load the trained model\n",
    "    # assert args.init_from_params, (\n",
    "    #    \"Please set init_from_params to load the infer model.\")\n",
    "    init_from_params='trained_models/step_final'\n",
    "    model_dict = paddle.load(\n",
    "        os.path.join(init_from_params, \"transformer.pdparams\"))\n",
    "\n",
    "    # To avoid a longer length than training, reset the size of position\n",
    "    # encoding to max_length\n",
    "    model_dict[\"encoder.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "    model_dict[\"decoder.pos_encoder.weight\"] = position_encoding_init(\n",
    "        args.max_length + 1, args.d_model)\n",
    "    transformer.load_dict(model_dict)\n",
    "\n",
    "    # Set evaluate mode\n",
    "    transformer.eval()\n",
    "\n",
    "    f = open(args.output_file, \"w\")\n",
    "    with paddle.no_grad():\n",
    "        for (src_word, ) in test_loader:\n",
    "            finished_seq = transformer(src_word=src_word)\n",
    "            finished_seq = finished_seq.numpy().transpose([0, 2, 1])\n",
    "            for ins in finished_seq:\n",
    "                for beam_idx, beam in enumerate(ins):\n",
    "                    if beam_idx >= args.n_best:\n",
    "                        break\n",
    "                    id_list = post_process_seq(beam, args.bos_idx, args.eos_idx)\n",
    "                    word_list = to_tokens(id_list)\n",
    "                    sequence = \" \".join(word_list) + \"\\n\"\n",
    "                    f.write(sequence)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "do_predict(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
